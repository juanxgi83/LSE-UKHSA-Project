{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92f09361",
   "metadata": {},
   "source": [
    "# 04: Fetch Abstracts for Referenced Studies\n",
    "\n",
    "## Objective\n",
    "Match our extracted references to PubMed records and fetch abstracts for LLM evaluation.\n",
    "\n",
    "## Matching Strategy (CrossRef-enhanced)\n",
    "\n",
    "This workflow uses a 3-phase approach for maximum match rate:\n",
    "\n",
    "1. **Direct Extraction** - Extract DOI/PMID directly from reference text using regex\n",
    "2. **CrossRef API** - For references without DOI, query CrossRef's bibliographic search\n",
    "3. **PubMed Lookup** - Use DOIs to fetch PMIDs, then batch-fetch abstracts\n",
    "\n",
    "## Why CrossRef?\n",
    "- CrossRef API (`query.bibliographic`) is specifically designed to match reference strings to DOIs\n",
    "- Handles fuzzy matching internally (typos, ligatures, formatting issues)\n",
    "- Has 130M+ DOIs - broader coverage than PubMed-only search\n",
    "- DOI → PMID lookup is highly reliable (~95%+ when the paper exists in PubMed)\n",
    "\n",
    "## Output\n",
    "- `Data/referenced_paper_abstracts.csv` - Abstracts with match confidence scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3896d1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q biopython pandas tqdm requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673bcff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: c:\\Users\\juanx\\Documents\\LSE-UKHSA Project\\Data\n",
      "NCBI API key configured: True\n",
      "NCBI rate: 9 requests/sec\n",
      "CrossRef rate: 2 requests/sec\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from Bio import Entrez\n",
    "from collections import Counter\n",
    "\n",
    "# =============================================================================\n",
    "# Configuration\n",
    "# =============================================================================\n",
    "\n",
    "# NCBI API configuration - with API key allows 10 requests/sec\n",
    "# Credentials loaded from .env file (never hardcode!)\n",
    "Entrez.email = os.environ.get(\"NCBI_EMAIL\", \"\")\n",
    "Entrez.api_key = os.environ.get(\"NCBI_API_KEY\", \"\")\n",
    "\n",
    "# Rate limits\n",
    "NCBI_RATE = 0.11 if Entrez.api_key else 0.34  # seconds between NCBI requests\n",
    "CROSSREF_RATE = 0.5  # seconds between CrossRef requests (polite)\n",
    "\n",
    "# Setup paths\n",
    "notebook_dir = Path.cwd()\n",
    "project_root = notebook_dir if (notebook_dir / \"Data\").exists() else notebook_dir.parent\n",
    "DATA_DIR = project_root / \"Data\"\n",
    "\n",
    "# Input\n",
    "REFS_CSV = DATA_DIR / \"categorized_references.csv\"\n",
    "META_CSV = DATA_DIR / \"review_metadata.csv\"\n",
    "\n",
    "# Output\n",
    "OUTPUT_CSV = DATA_DIR / \"referenced_paper_abstracts.csv\"\n",
    "PROGRESS_CSV = DATA_DIR / \"crossref_matching_progress.csv\"\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"NCBI API key configured: {bool(Entrez.api_key)}\")\n",
    "print(f\"NCBI rate: {1/NCBI_RATE:.0f} requests/sec\")\n",
    "print(f\"CrossRef rate: {1/CROSSREF_RATE:.0f} requests/sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7e564d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total references: 629,561\n",
      "\n",
      "Public health reviews: 1,349\n",
      "Groups: Public Health (79), Tobacco Addiction (231), Drugs and Alcohol (188), Infectious Diseases (361), Acute Respiratory Infections (463), STI (27)\n",
      "\n",
      "References after PH filter: 66,608\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Load and Filter to Public Health Reviews\n",
    "# =============================================================================\n",
    "\n",
    "# Load all references\n",
    "refs_df = pd.read_csv(REFS_CSV)\n",
    "print(f\"Total references: {len(refs_df):,}\")\n",
    "\n",
    "# Load metadata for filtering\n",
    "meta_df = pd.read_csv(META_CSV)\n",
    "\n",
    "# Define core public health Cochrane groups\n",
    "PUBLIC_HEALTH_GROUPS = [\n",
    "    'Public Health',\n",
    "    'Tobacco Addiction', \n",
    "    'Drugs and Alcohol',\n",
    "    'Infectious Diseases',\n",
    "    'Acute Respiratory Infections',\n",
    "    'HIV/AIDS',\n",
    "    'STI',\n",
    "]\n",
    "\n",
    "# Filter to PH reviews\n",
    "ph_reviews = meta_df[meta_df['cochrane_group'].isin(PUBLIC_HEALTH_GROUPS)]\n",
    "ph_review_dois = set(ph_reviews['doi'].dropna())\n",
    "\n",
    "print(f\"\\nPublic health reviews: {len(ph_reviews):,}\")\n",
    "print(\"Groups:\", \", \".join([f\"{g} ({(ph_reviews['cochrane_group']==g).sum()})\" \n",
    "                            for g in PUBLIC_HEALTH_GROUPS if (ph_reviews['cochrane_group']==g).sum() > 0]))\n",
    "\n",
    "# Filter references\n",
    "refs_df = refs_df[refs_df['review_doi'].isin(ph_review_dois)].copy()\n",
    "print(f\"\\nReferences after PH filter: {len(refs_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a46a4d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total references: 66,608\n",
      "Unique references: 41,840\n",
      "Deduplication ratio: 1.6x\n",
      "\n",
      "Categories:\n",
      "category\n",
      "excluded    26885\n",
      "included    13025\n",
      "awaiting     1217\n",
      "ongoing       713\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Deduplicate References\n",
    "# =============================================================================\n",
    "\n",
    "def create_ref_signature(row):\n",
    "    \"\"\"Create a normalized signature for deduplication.\"\"\"\n",
    "    title = str(row.get('title', '')).lower().strip()[:100]\n",
    "    year = str(row.get('year', ''))\n",
    "    first_author = str(row.get('authors', '')).split()[0].lower() if row.get('authors') else ''\n",
    "    return f\"{first_author}|{year}|{title[:50]}\"\n",
    "\n",
    "refs_df['signature'] = refs_df.apply(create_ref_signature, axis=1)\n",
    "unique_refs = refs_df.drop_duplicates(subset='signature').copy()\n",
    "\n",
    "print(f\"Total references: {len(refs_df):,}\")\n",
    "print(f\"Unique references: {len(unique_refs):,}\")\n",
    "print(f\"Deduplication ratio: {len(refs_df)/len(unique_refs):.1f}x\")\n",
    "print(f\"\\nCategories:\")\n",
    "print(unique_refs['category'].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ee8ae3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE 1: Direct Extraction\n",
      "============================================================\n",
      "References with DOI: 2,746 (6.6%)\n",
      "References with PMID: 993 (2.4%)\n",
      "Need CrossRef lookup: 39,094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juanx\\AppData\\Local\\Temp\\ipykernel_81992\\1551778175.py:41: FutureWarning: The behavior of array concatenation with empty entries is deprecated. In a future version, this will no longer exclude empty items when determining the result dtype. To retain the old behavior, exclude the empty entries before the concat operation.\n",
      "  unique_refs['final_pmid'] = unique_refs['extracted_pmid'].combine_first(unique_refs.get('pmid'))\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PHASE 1: Extract DOI/PMID directly from reference text\n",
    "# =============================================================================\n",
    "# Many references already have DOI or PMID embedded in the text\n",
    "\n",
    "def extract_pmid(text):\n",
    "    \"\"\"Extract PMID from reference text.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    match = re.search(r\"(PMID|PUBMED|MEDLINE)[:\\s]*(\\d+)\", str(text), flags=re.I)\n",
    "    if match:\n",
    "        return match.group(2)\n",
    "    return None\n",
    "\n",
    "def extract_doi(text):\n",
    "    \"\"\"Extract DOI from reference text.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    match = re.search(\n",
    "        r\"(?:DOI[:\\s]*|HTTPS?://(?:DX\\.)?DOI\\.ORG/)?(10\\.\\d{4,9}/[-._;()/:A-Z0-9]+)\", \n",
    "        str(text), flags=re.I\n",
    "    )\n",
    "    if match:\n",
    "        doi = match.group(1)\n",
    "        return doi.rstrip(\".,;)\")  # remove trailing punctuation\n",
    "    return None\n",
    "\n",
    "# Build full reference text for extraction\n",
    "unique_refs['full_ref'] = (\n",
    "    unique_refs['title'].fillna('') + ' ' + \n",
    "    unique_refs['authors'].fillna('') + ' ' +\n",
    "    unique_refs['year'].fillna('').astype(str)\n",
    ")\n",
    "\n",
    "# Extract DOI and PMID\n",
    "unique_refs['extracted_doi'] = unique_refs['full_ref'].apply(extract_doi)\n",
    "unique_refs['extracted_pmid'] = unique_refs['full_ref'].apply(extract_pmid)\n",
    "\n",
    "# Also use ref_doi and pmid columns if available\n",
    "unique_refs['final_doi'] = unique_refs['extracted_doi'].combine_first(unique_refs.get('ref_doi'))\n",
    "unique_refs['final_pmid'] = unique_refs['extracted_pmid'].combine_first(unique_refs.get('pmid'))\n",
    "\n",
    "has_doi = unique_refs['final_doi'].notna().sum()\n",
    "has_pmid = unique_refs['final_pmid'].notna().sum()\n",
    "\n",
    "print(\"PHASE 1: Direct Extraction\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"References with DOI: {has_doi:,} ({has_doi/len(unique_refs)*100:.1f}%)\")\n",
    "print(f\"References with PMID: {has_pmid:,} ({has_pmid/len(unique_refs)*100:.1f}%)\")\n",
    "print(f\"Need CrossRef lookup: {len(unique_refs) - has_doi:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5ff427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API functions defined:\n",
      "  • get_doi_from_crossref() - CrossRef bibliographic search\n",
      "  • get_pmid_from_doi() - DOI to PMID lookup\n",
      "  • fetch_abstracts_batch() - Batch PubMed fetch\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CrossRef and PubMed API Functions\n",
    "# =============================================================================\n",
    "\n",
    "def clean_reference(ref):\n",
    "    \"\"\"Clean reference text for CrossRef query.\"\"\"\n",
    "    if pd.isna(ref):\n",
    "        return \"\"\n",
    "    ref = str(ref)\n",
    "    # Remove Cochrane-specific text\n",
    "    ref = re.sub(r\"\\(REVIEW\\).*\", \"\", ref, flags=re.I)\n",
    "    ref = re.sub(r\"TRUSTED EVIDENCE.*\", \"\", ref, flags=re.I)\n",
    "    ref = re.sub(r\"COCHRANE.*?LIBRARY\", \"\", ref, flags=re.I)\n",
    "    # Remove page markers\n",
    "    ref = re.sub(r\"---\\s*Page\\s*\\d+\\s*---\", \" \", ref)\n",
    "    # Remove excessive whitespace\n",
    "    ref = re.sub(r\"\\s{2,}\", \" \", ref)\n",
    "    return ref.strip()\n",
    "\n",
    "\n",
    "def get_doi_from_crossref(ref, timeout=10):\n",
    "    \"\"\"Query CrossRef API to get DOI from bibliographic reference.\"\"\"\n",
    "    if not ref or len(ref) < 20:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        url = \"https://api.crossref.org/works\"\n",
    "        params = {\"query.bibliographic\": ref, \"rows\": 1}\n",
    "        headers = {\"User-Agent\": f\"LSE-UKHSA-Project/1.0 (mailto:{Entrez.email})\" if Entrez.email else \"LSE-UKHSA-Project/1.0\"}\n",
    "        \n",
    "        r = requests.get(url, params=params, headers=headers, timeout=timeout)\n",
    "        r.raise_for_status()\n",
    "        \n",
    "        items = r.json().get(\"message\", {}).get(\"items\", [])\n",
    "        if items:\n",
    "            return items[0].get(\"DOI\")\n",
    "    except Exception as e:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_pmid_from_doi(doi, api_key=None):\n",
    "    \"\"\"Look up PMID from DOI via PubMed.\"\"\"\n",
    "    if not doi:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        params = {\n",
    "            \"db\": \"pubmed\",\n",
    "            \"term\": f\"{doi}[DOI]\",\n",
    "            \"retmode\": \"json\"\n",
    "        }\n",
    "        if api_key:\n",
    "            params[\"api_key\"] = api_key\n",
    "            \n",
    "        r = requests.get(\n",
    "            \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\",\n",
    "            params=params, timeout=10\n",
    "        )\n",
    "        data = r.json()\n",
    "        idlist = data.get(\"esearchresult\", {}).get(\"idlist\", [])\n",
    "        return idlist[0] if idlist else None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def fetch_abstracts_batch(pmids, batch_size=200, max_retries=3):\n",
    "    \"\"\"Batch fetch PubMed records (200 per request) with retry logic.\"\"\"\n",
    "    results = {}\n",
    "    pmid_list = [str(int(p)) for p in pmids if pd.notna(p) and str(p).isdigit()]\n",
    "    failed_batches = []\n",
    "    \n",
    "    for i in range(0, len(pmid_list), batch_size):\n",
    "        batch = pmid_list[i:i + batch_size]\n",
    "        success = False\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                time.sleep(NCBI_RATE * (attempt + 1))  # Exponential backoff\n",
    "                handle = Entrez.efetch(db=\"pubmed\", id=\",\".join(batch), rettype=\"xml\", retmode=\"xml\")\n",
    "                records = Entrez.read(handle)\n",
    "                handle.close()\n",
    "                \n",
    "                for article in records.get('PubmedArticle', []):\n",
    "                    data = extract_record_data(article)\n",
    "                    if data:\n",
    "                        results[data['pmid']] = data\n",
    "                success = True\n",
    "                break\n",
    "            except Exception as e:\n",
    "                if attempt < max_retries - 1:\n",
    "                    print(f\"Batch {i//batch_size + 1} attempt {attempt + 1} failed: {e}, retrying...\")\n",
    "                else:\n",
    "                    print(f\"Batch {i//batch_size + 1} failed after {max_retries} attempts: {e}\")\n",
    "                    failed_batches.append(batch)\n",
    "    \n",
    "    if failed_batches:\n",
    "        print(f\"Warning: {len(failed_batches)} batch(es) failed permanently ({sum(len(b) for b in failed_batches)} PMIDs)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def extract_record_data(record):\n",
    "    \"\"\"Extract fields from PubMed record.\"\"\"\n",
    "    try:\n",
    "        article = record['MedlineCitation']['Article']\n",
    "        pmid = str(record['MedlineCitation']['PMID'])\n",
    "        title = str(article.get('ArticleTitle', ''))\n",
    "        \n",
    "        # Abstract\n",
    "        abstract = ''\n",
    "        if 'Abstract' in article and 'AbstractText' in article['Abstract']:\n",
    "            parts = article['Abstract']['AbstractText']\n",
    "            abstract = ' '.join([str(p) for p in parts]) if isinstance(parts, list) else str(parts)\n",
    "        \n",
    "        # Year\n",
    "        year = ''\n",
    "        if 'Journal' in article and 'JournalIssue' in article['Journal']:\n",
    "            year = article['Journal']['JournalIssue'].get('PubDate', {}).get('Year', '')\n",
    "        \n",
    "        # Authors\n",
    "        authors = []\n",
    "        if 'AuthorList' in article:\n",
    "            for auth in article['AuthorList']:\n",
    "                if 'LastName' in auth:\n",
    "                    name = auth['LastName'] + (' ' + auth.get('Initials', ''))\n",
    "                    authors.append(name.strip())\n",
    "        \n",
    "        # DOI\n",
    "        doi = ''\n",
    "        if 'ELocationID' in article:\n",
    "            for loc in article['ELocationID']:\n",
    "                if loc.attributes.get('EIdType') == 'doi':\n",
    "                    doi = str(loc)\n",
    "                    break\n",
    "        \n",
    "        return {\n",
    "            'pmid': pmid, 'title': title, 'abstract': abstract,\n",
    "            'year': year, 'authors': '; '.join(authors), 'doi': doi\n",
    "        }\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "print(\"API functions defined:\")\n",
    "print(\"  • get_doi_from_crossref() - CrossRef bibliographic search\")\n",
    "print(\"  • get_pmid_from_doi() - DOI to PMID lookup\")\n",
    "print(\"  • fetch_abstracts_batch() - Batch PubMed fetch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fe3d0444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE 2: CrossRef DOI Lookup\n",
      "============================================================\n",
      "References needing CrossRef: 39,094\n",
      "Estimated time: ~5.4 hours\n",
      "Resuming from checkpoint: 32,130 already processed\n",
      "Remaining to process: 0\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PHASE 2: CrossRef lookup for missing DOIs\n",
    "# =============================================================================\n",
    "# Query CrossRef API for references without DOI\n",
    "# Progress saved every 500 refs\n",
    "\n",
    "print(\"PHASE 2: CrossRef DOI Lookup\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# References that need CrossRef lookup\n",
    "refs_need_crossref = unique_refs[unique_refs['final_doi'].isna()].copy()\n",
    "print(f\"References needing CrossRef: {len(refs_need_crossref):,}\")\n",
    "\n",
    "# Time estimate\n",
    "est_hours = len(refs_need_crossref) * CROSSREF_RATE / 3600\n",
    "print(f\"Estimated time: ~{est_hours:.1f} hours\")\n",
    "\n",
    "# Check for existing progress\n",
    "if PROGRESS_CSV.exists():\n",
    "    progress_df = pd.read_csv(PROGRESS_CSV)\n",
    "    already_done = set(progress_df['study_id'])\n",
    "    print(f\"Resuming from checkpoint: {len(already_done):,} already processed\")\n",
    "else:\n",
    "    progress_df = pd.DataFrame()\n",
    "    already_done = set()\n",
    "\n",
    "# Filter to remaining refs\n",
    "refs_to_process = refs_need_crossref[~refs_need_crossref['study_id'].isin(already_done)]\n",
    "print(f\"Remaining to process: {len(refs_to_process):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b52c2964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af2f21d746d24e1095d1333768eea712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CrossRef:   0%|          | 0/39094 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[500/39,094] Saved. Match rate: 99.6% (2557/hr)\n",
      "\n",
      "[1,000/39,094] Saved. Match rate: 99.8% (2742/hr)\n",
      "\n",
      "[1,500/39,094] Saved. Match rate: 99.9% (2844/hr)\n",
      "\n",
      "[2,000/39,094] Saved. Match rate: 99.8% (2881/hr)\n",
      "\n",
      "[2,500/39,094] Saved. Match rate: 99.8% (2881/hr)\n",
      "\n",
      "[3,000/39,094] Saved. Match rate: 99.8% (2931/hr)\n",
      "\n",
      "[3,500/39,094] Saved. Match rate: 99.8% (2949/hr)\n",
      "\n",
      "[4,000/39,094] Saved. Match rate: 99.8% (2942/hr)\n",
      "\n",
      "[4,500/39,094] Saved. Match rate: 99.8% (2959/hr)\n",
      "\n",
      "[5,000/39,094] Saved. Match rate: 99.8% (2952/hr)\n",
      "\n",
      "[5,500/39,094] Saved. Match rate: 99.8% (2969/hr)\n",
      "\n",
      "[6,000/39,094] Saved. Match rate: 99.8% (2982/hr)\n",
      "\n",
      "[6,500/39,094] Saved. Match rate: 99.8% (2986/hr)\n",
      "\n",
      "[7,000/39,094] Saved. Match rate: 99.8% (2996/hr)\n",
      "\n",
      "[7,500/39,094] Saved. Match rate: 99.9% (3007/hr)\n",
      "\n",
      "[8,000/39,094] Saved. Match rate: 99.9% (3017/hr)\n",
      "\n",
      "[8,500/39,094] Saved. Match rate: 99.7% (2918/hr)\n",
      "\n",
      "[9,000/39,094] Saved. Match rate: 99.7% (2898/hr)\n",
      "\n",
      "[9,500/39,094] Saved. Match rate: 99.7% (2867/hr)\n",
      "\n",
      "[10,000/39,094] Saved. Match rate: 99.7% (2864/hr)\n",
      "\n",
      "[10,500/39,094] Saved. Match rate: 99.7% (2857/hr)\n",
      "\n",
      "[11,000/39,094] Saved. Match rate: 99.8% (2845/hr)\n",
      "\n",
      "[11,500/39,094] Saved. Match rate: 99.7% (2821/hr)\n",
      "\n",
      "[12,000/39,094] Saved. Match rate: 99.7% (2794/hr)\n",
      "\n",
      "[12,500/39,094] Saved. Match rate: 99.7% (2757/hr)\n",
      "\n",
      "[13,000/39,094] Saved. Match rate: 99.7% (2757/hr)\n",
      "\n",
      "[13,500/39,094] Saved. Match rate: 99.7% (2696/hr)\n",
      "\n",
      "[14,000/39,094] Saved. Match rate: 99.7% (2697/hr)\n",
      "\n",
      "[14,500/39,094] Saved. Match rate: 99.7% (2691/hr)\n",
      "\n",
      "[15,000/39,094] Saved. Match rate: 99.7% (2694/hr)\n",
      "\n",
      "[15,500/39,094] Saved. Match rate: 99.7% (2708/hr)\n",
      "\n",
      "[16,000/39,094] Saved. Match rate: 99.7% (2722/hr)\n",
      "\n",
      "[16,500/39,094] Saved. Match rate: 99.8% (2735/hr)\n",
      "\n",
      "[17,000/39,094] Saved. Match rate: 99.8% (2746/hr)\n",
      "\n",
      "[17,500/39,094] Saved. Match rate: 99.8% (2750/hr)\n",
      "\n",
      "[18,000/39,094] Saved. Match rate: 99.8% (2753/hr)\n",
      "\n",
      "[18,500/39,094] Saved. Match rate: 99.7% (2761/hr)\n",
      "\n",
      "[19,000/39,094] Saved. Match rate: 99.7% (2772/hr)\n",
      "\n",
      "[19,500/39,094] Saved. Match rate: 99.8% (2782/hr)\n",
      "\n",
      "[20,000/39,094] Saved. Match rate: 99.7% (2781/hr)\n",
      "\n",
      "[20,500/39,094] Saved. Match rate: 99.7% (2783/hr)\n",
      "\n",
      "[21,000/39,094] Saved. Match rate: 99.7% (2782/hr)\n",
      "\n",
      "[21,500/39,094] Saved. Match rate: 99.7% (2780/hr)\n",
      "\n",
      "[22,000/39,094] Saved. Match rate: 99.8% (2781/hr)\n",
      "\n",
      "[22,500/39,094] Saved. Match rate: 99.8% (2782/hr)\n",
      "\n",
      "[23,000/39,094] Saved. Match rate: 99.8% (2779/hr)\n",
      "\n",
      "[23,500/39,094] Saved. Match rate: 99.8% (2777/hr)\n",
      "\n",
      "[24,000/39,094] Saved. Match rate: 99.8% (2780/hr)\n",
      "\n",
      "[24,500/39,094] Saved. Match rate: 99.8% (2781/hr)\n",
      "\n",
      "[25,000/39,094] Saved. Match rate: 99.8% (2782/hr)\n",
      "\n",
      "[25,500/39,094] Saved. Match rate: 99.8% (2781/hr)\n",
      "\n",
      "[26,000/39,094] Saved. Match rate: 99.8% (2780/hr)\n",
      "\n",
      "[26,500/39,094] Saved. Match rate: 99.8% (2778/hr)\n",
      "\n",
      "[27,000/39,094] Saved. Match rate: 99.8% (2769/hr)\n",
      "\n",
      "[27,500/39,094] Saved. Match rate: 99.8% (2767/hr)\n",
      "\n",
      "[28,000/39,094] Saved. Match rate: 99.8% (2756/hr)\n",
      "\n",
      "[28,500/39,094] Saved. Match rate: 99.8% (2750/hr)\n",
      "\n",
      "[29,000/39,094] Saved. Match rate: 99.8% (2743/hr)\n",
      "\n",
      "[29,500/39,094] Saved. Match rate: 99.8% (2741/hr)\n",
      "\n",
      "[30,000/39,094] Saved. Match rate: 99.8% (2745/hr)\n",
      "\n",
      "[30,500/39,094] Saved. Match rate: 99.8% (2747/hr)\n",
      "\n",
      "[31,000/39,094] Saved. Match rate: 99.8% (2744/hr)\n",
      "\n",
      "[31,500/39,094] Saved. Match rate: 99.8% (2747/hr)\n",
      "\n",
      "[32,000/39,094] Saved. Match rate: 99.8% (2751/hr)\n",
      "\n",
      "[32,500/39,094] Saved. Match rate: 99.8% (2756/hr)\n",
      "\n",
      "[33,000/39,094] Saved. Match rate: 99.8% (2758/hr)\n",
      "\n",
      "[33,500/39,094] Saved. Match rate: 99.8% (2759/hr)\n",
      "\n",
      "[34,000/39,094] Saved. Match rate: 99.8% (2761/hr)\n",
      "\n",
      "[34,500/39,094] Saved. Match rate: 99.8% (2765/hr)\n",
      "\n",
      "[35,000/39,094] Saved. Match rate: 99.8% (2769/hr)\n",
      "\n",
      "[35,500/39,094] Saved. Match rate: 99.8% (2773/hr)\n",
      "\n",
      "[36,000/39,094] Saved. Match rate: 99.8% (2777/hr)\n",
      "\n",
      "[36,500/39,094] Saved. Match rate: 99.8% (2781/hr)\n",
      "\n",
      "[37,000/39,094] Saved. Match rate: 99.8% (2783/hr)\n",
      "\n",
      "[37,500/39,094] Saved. Match rate: 99.8% (2787/hr)\n",
      "\n",
      "[38,000/39,094] Saved. Match rate: 99.8% (2786/hr)\n",
      "\n",
      "[38,500/39,094] Saved. Match rate: 99.8% (2787/hr)\n",
      "\n",
      "[39,000/39,094] Saved. Match rate: 99.8% (2784/hr)\n",
      "\n",
      "✓ CrossRef complete: 39,031 DOIs found (99.8%)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PHASE 2 EXECUTION: CrossRef DOI Lookup\n",
    "# =============================================================================\n",
    "\n",
    "results = []\n",
    "start_time = time.time()\n",
    "matched_count = 0\n",
    "\n",
    "for idx, (_, row) in enumerate(tqdm(refs_to_process.iterrows(), total=len(refs_to_process), desc=\"CrossRef\")):\n",
    "    # Build reference string for CrossRef query\n",
    "    ref_text = clean_reference(f\"{row['title']} {row['authors']} {row['year']}\")\n",
    "    \n",
    "    # Query CrossRef\n",
    "    crossref_doi = get_doi_from_crossref(ref_text)\n",
    "    time.sleep(CROSSREF_RATE)\n",
    "    \n",
    "    # Record result\n",
    "    results.append({\n",
    "        'study_id': row['study_id'],\n",
    "        'category': row['category'],\n",
    "        'original_title': row['title'],\n",
    "        'original_authors': row['authors'],\n",
    "        'original_year': row['year'],\n",
    "        'crossref_doi': crossref_doi,\n",
    "        'match_method': 'crossref' if crossref_doi else 'no_match'\n",
    "    })\n",
    "    \n",
    "    if crossref_doi:\n",
    "        matched_count += 1\n",
    "    \n",
    "    # Save progress every 500 refs\n",
    "    if (idx + 1) % 500 == 0:\n",
    "        batch_df = pd.DataFrame(results)\n",
    "        combined = pd.concat([progress_df, batch_df], ignore_index=True)\n",
    "        combined.to_csv(PROGRESS_CSV, index=False)\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        rate = (idx + 1) / elapsed * 3600\n",
    "        print(f\"\\n[{idx+1:,}/{len(refs_to_process):,}] Saved. Match rate: {matched_count/(idx+1)*100:.1f}% ({rate:.0f}/hr)\")\n",
    "\n",
    "# Final save\n",
    "if results:\n",
    "    batch_df = pd.DataFrame(results)\n",
    "    combined = pd.concat([progress_df, batch_df], ignore_index=True)\n",
    "    combined.to_csv(PROGRESS_CSV, index=False)\n",
    "\n",
    "print(f\"\\n✓ CrossRef complete: {matched_count:,} DOIs found ({matched_count/len(refs_to_process)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4aae098f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE 3: DOI → PMID Conversion\n",
      "============================================================\n",
      "Total unique DOIs: 31,927\n",
      "Loaded 23,302 cached DOI→PMID mappings\n",
      "Loaded 8,608 cached NO_PMID entries (not in PubMed)\n",
      "DOIs needing lookup: 17\n",
      "Converting DOIs to PMIDs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c5711170dbe4332a381de18026531e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "DOI→PMID:   0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n✓ Found 0 new PMIDs, cache updated\n",
      "\\n✓ Total PMIDs available: 23,302 (73.0%)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PHASE 3: Convert DOIs to PMIDs\n",
    "# =============================================================================\n",
    "\n",
    "print(\"PHASE 3: DOI → PMID Conversion\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Reload unique_refs fresh (to avoid column conflicts from previous runs)\n",
    "unique_refs_fresh = refs_df.drop_duplicates(subset='signature').copy()\n",
    "\n",
    "# Re-extract DOIs (Phase 1 logic)\n",
    "unique_refs_fresh['full_ref'] = (\n",
    "    unique_refs_fresh['title'].fillna('') + ' ' + \n",
    "    unique_refs_fresh['authors'].fillna('') + ' ' +\n",
    "    unique_refs_fresh['year'].fillna('').astype(str)\n",
    ")\n",
    "unique_refs_fresh['extracted_doi'] = unique_refs_fresh['full_ref'].apply(extract_doi)\n",
    "unique_refs_fresh['final_doi'] = unique_refs_fresh['extracted_doi']\n",
    "\n",
    "# Combine with CrossRef DOIs\n",
    "crossref_results = pd.read_csv(PROGRESS_CSV) if PROGRESS_CSV.exists() else pd.DataFrame()\n",
    "\n",
    "if len(crossref_results) > 0:\n",
    "    # Merge on normalized title (not study_id!) to correctly match different papers\n",
    "    crossref_results['title_normalized'] = crossref_results['original_title'].str.lower().str.strip()\n",
    "    unique_refs_fresh['title_normalized'] = unique_refs_fresh['title'].str.lower().str.strip()\n",
    "    \n",
    "    crossref_doi_map = crossref_results[['title_normalized', 'crossref_doi']].drop_duplicates()\n",
    "    unique_refs_fresh = unique_refs_fresh.merge(\n",
    "        crossref_doi_map,\n",
    "        on='title_normalized',\n",
    "        how='left'\n",
    "    )\n",
    "    unique_refs_fresh['final_doi'] = unique_refs_fresh['final_doi'].combine_first(unique_refs_fresh['crossref_doi'])\n",
    "\n",
    "# Update the main variable\n",
    "unique_refs = unique_refs_fresh\n",
    "\n",
    "# Get all unique DOIs\n",
    "all_dois = unique_refs[unique_refs['final_doi'].notna()]['final_doi'].str.lower().unique()\n",
    "print(f\"Total unique DOIs: {len(all_dois):,}\")\n",
    "\n",
    "# DOI→PMID cache file\n",
    "DOI_PMID_CACHE = DATA_DIR / \"doi_pmid_cache.csv\"\n",
    "\n",
    "# Load cached mappings if available (includes NO_PMID entries for DOIs without PubMed records)\n",
    "doi_to_pmid = {}\n",
    "no_pmid_cached = 0\n",
    "if DOI_PMID_CACHE.exists():\n",
    "    cache_df = pd.read_csv(DOI_PMID_CACHE)\n",
    "    for _, row in cache_df.iterrows():\n",
    "        doi = str(row['doi']).lower()\n",
    "        pmid = str(row['pmid'])\n",
    "        if pmid != 'NO_PMID':\n",
    "            doi_to_pmid[doi] = pmid\n",
    "        else:\n",
    "            doi_to_pmid[doi] = None  # Mark as \"looked up, no result\"\n",
    "            no_pmid_cached += 1\n",
    "    print(f\"Loaded {len(doi_to_pmid) - no_pmid_cached:,} cached DOI→PMID mappings\")\n",
    "    print(f\"Loaded {no_pmid_cached:,} cached NO_PMID entries (not in PubMed)\")\n",
    "\n",
    "# Find DOIs not in cache at all\n",
    "dois_to_lookup = [d for d in all_dois if d.lower() not in doi_to_pmid]\n",
    "print(f\"DOIs needing lookup: {len(dois_to_lookup):,}\")\n",
    "\n",
    "# Convert DOIs to PMIDs (only for uncached)\n",
    "if dois_to_lookup:\n",
    "    print(\"Converting DOIs to PMIDs...\")\n",
    "    new_mappings = 0\n",
    "    for doi in tqdm(dois_to_lookup, desc=\"DOI→PMID\"):\n",
    "        pmid = get_pmid_from_doi(doi, Entrez.api_key)\n",
    "        if pmid:\n",
    "            doi_to_pmid[doi.lower()] = pmid\n",
    "            new_mappings += 1\n",
    "        else:\n",
    "            doi_to_pmid[doi.lower()] = None  # Cache the \"no result\" too\n",
    "        time.sleep(NCBI_RATE)\n",
    "    \n",
    "    # Save updated cache (convert None to 'NO_PMID' for storage)\n",
    "    cache_rows = [{'doi': k, 'pmid': v if v else 'NO_PMID'} for k, v in doi_to_pmid.items()]\n",
    "    cache_df = pd.DataFrame(cache_rows)\n",
    "    cache_df.to_csv(DOI_PMID_CACHE, index=False)\n",
    "    print(f\"\\\\n✓ Found {new_mappings:,} new PMIDs, cache updated\")\n",
    "\n",
    "# Count actual PMIDs (not None)\n",
    "actual_pmids = sum(1 for v in doi_to_pmid.values() if v is not None)\n",
    "print(f\"\\\\n✓ Total PMIDs available: {actual_pmids:,} ({actual_pmids/len(all_dois)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c3e7a3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE 4: Fetch Abstracts\n",
      "============================================================\n",
      "Total unique PMIDs: 23,182\n",
      "Fetching abstracts in batches...\n",
      "\n",
      "✓ Fetched 23,173 records in 602s\n",
      "  With abstracts: 20,942 (90.4%)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PHASE 4: Batch Fetch Abstracts\n",
    "# =============================================================================\n",
    "\n",
    "print(\"PHASE 4: Fetch Abstracts\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Map DOIs to PMIDs\n",
    "unique_refs['doi_lower'] = unique_refs['final_doi'].str.lower()\n",
    "unique_refs['pmid_from_doi'] = unique_refs['doi_lower'].map(doi_to_pmid)\n",
    "\n",
    "# Initialize final_pmid if it doesn't exist (fresh dataframe)\n",
    "if 'final_pmid' not in unique_refs.columns:\n",
    "    unique_refs['final_pmid'] = None\n",
    "unique_refs['final_pmid'] = unique_refs['final_pmid'].combine_first(unique_refs['pmid_from_doi'])\n",
    "\n",
    "# Get all unique PMIDs\n",
    "all_pmids = unique_refs[unique_refs['final_pmid'].notna()]['final_pmid'].unique()\n",
    "print(f\"Total unique PMIDs: {len(all_pmids):,}\")\n",
    "\n",
    "# Batch fetch abstracts\n",
    "print(\"Fetching abstracts in batches...\")\n",
    "start = time.time()\n",
    "abstract_records = fetch_abstracts_batch(all_pmids, batch_size=200)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "print(f\"\\n✓ Fetched {len(abstract_records):,} records in {elapsed:.0f}s\")\n",
    "with_abstract = sum(1 for r in abstract_records.values() if r.get('abstract'))\n",
    "print(f\"  With abstracts: {with_abstract:,} ({with_abstract/len(abstract_records)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d8798a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling final results...\n",
      "============================================================\n",
      "Abstract data built for 41,840 unique signatures\n",
      "\n",
      "Total references: 66,608\n",
      "Unique (study_id, review_doi) pairs: 66,562\n",
      "\n",
      "Match methods:\n",
      "match_method\n",
      "crossref      47121\n",
      "no_match      19090\n",
      "doi_direct      397\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Compile Final Results\n",
    "# =============================================================================\n",
    "# Re-expand abstract data to ALL (study_id, review_doi) pairs via signature\n",
    "\n",
    "print(\"Compiling final results...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Build abstract data keyed by signature (from unique_refs)\n",
    "signature_to_abstract = {}\n",
    "\n",
    "for _, row in unique_refs.iterrows():\n",
    "    sig = row['signature']\n",
    "    pmid = str(row['final_pmid']) if pd.notna(row['final_pmid']) else None\n",
    "    record = abstract_records.get(pmid, {}) if pmid else {}\n",
    "    \n",
    "    # Determine match method\n",
    "    if pd.notna(row.get('extracted_pmid')):\n",
    "        method = 'pmid_direct'\n",
    "    elif pd.notna(row.get('extracted_doi')) or pd.notna(row.get('ref_doi')):\n",
    "        method = 'doi_direct'\n",
    "    elif pd.notna(row.get('crossref_doi')):\n",
    "        method = 'crossref'\n",
    "    else:\n",
    "        method = 'no_match'\n",
    "    \n",
    "    signature_to_abstract[sig] = {\n",
    "        'pmid': pmid,\n",
    "        'doi': row['final_doi'],\n",
    "        'matched_title': record.get('title', ''),\n",
    "        'matched_authors': record.get('authors', ''),\n",
    "        'matched_year': record.get('year', ''),\n",
    "        'abstract': record.get('abstract', ''),\n",
    "        'match_method': method if pmid else 'no_match'\n",
    "    }\n",
    "\n",
    "print(f\"Abstract data built for {len(signature_to_abstract):,} unique signatures\")\n",
    "\n",
    "# Re-expand to ALL original (study_id, review_doi) pairs\n",
    "output_rows = []\n",
    "\n",
    "for _, row in refs_df.iterrows():\n",
    "    sig = row['signature']\n",
    "    abstract_data = signature_to_abstract.get(sig, {})\n",
    "    \n",
    "    output_rows.append({\n",
    "        'study_id': row['study_id'],\n",
    "        'review_doi': row['review_doi'],\n",
    "        'category': row['category'],\n",
    "        'original_title': row['title'],\n",
    "        'original_authors': row['authors'],\n",
    "        'original_year': row['year'],\n",
    "        'pmid': abstract_data.get('pmid'),\n",
    "        'doi': abstract_data.get('doi'),\n",
    "        'matched_title': abstract_data.get('matched_title', ''),\n",
    "        'matched_authors': abstract_data.get('matched_authors', ''),\n",
    "        'matched_year': abstract_data.get('matched_year', ''),\n",
    "        'abstract': abstract_data.get('abstract', ''),\n",
    "        'match_method': abstract_data.get('match_method', 'no_match')\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(output_rows)\n",
    "\n",
    "print(f\"\\nTotal references: {len(results_df):,}\")\n",
    "print(f\"Unique (study_id, review_doi) pairs: {results_df.groupby(['study_id', 'review_doi']).ngroups:,}\")\n",
    "print(f\"\\nMatch methods:\")\n",
    "print(results_df['match_method'].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0d332275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL RESULTS\n",
      "============================================================\n",
      "Total matched: 47,518 / 66,608 (71.3%)\n",
      "Unique (study_id, review_doi) pairs: 47,483\n",
      "\n",
      "By category:\n",
      "category\n",
      "excluded    30384\n",
      "included    15921\n",
      "awaiting      719\n",
      "ongoing       494\n",
      "\n",
      "With abstracts: 42,873 (90.2%)\n",
      "\n",
      "✓ Columns in output: ['study_id', 'review_doi', 'category', 'original_title', 'original_authors', 'original_year', 'pmid', 'doi', 'matched_title', 'matched_authors', 'matched_year', 'abstract', 'match_method']\n",
      "\n",
      "✓ Saved to c:\\Users\\juanx\\Documents\\LSE-UKHSA Project\\Data\\referenced_paper_abstracts.csv\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Save Final Output (with review_doi preserved!)\n",
    "# =============================================================================\n",
    "\n",
    "# Filter to matched only\n",
    "matched_refs = results_df[results_df['match_method'] != 'no_match'].copy()\n",
    "\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total matched: {len(matched_refs):,} / {len(results_df):,} ({len(matched_refs)/len(results_df)*100:.1f}%)\")\n",
    "print(f\"Unique (study_id, review_doi) pairs: {matched_refs.groupby(['study_id', 'review_doi']).ngroups:,}\")\n",
    "print(f\"\\nBy category:\")\n",
    "print(matched_refs['category'].value_counts().to_string())\n",
    "\n",
    "has_abstract = matched_refs['abstract'].str.len() > 0\n",
    "print(f\"\\nWith abstracts: {has_abstract.sum():,} ({has_abstract.mean()*100:.1f}%)\")\n",
    "\n",
    "# Verify review_doi is in output\n",
    "print(f\"\\n✓ Columns in output: {matched_refs.columns.tolist()}\")\n",
    "\n",
    "# Save\n",
    "matched_refs.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"\\n✓ Saved to {OUTPUT_CSV}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "16ea7ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PIPELINE SUMMARY\n",
      "============================================================\n",
      "\n",
      "Input: 46,309 unique references from public health reviews\n",
      "\n",
      "Phase 1 - Direct extraction:\n",
      "  DOIs extracted: 279\n",
      "\n",
      "Phase 2 - CrossRef lookup:\n",
      "  DOIs found: 39,031 / 39,094 (99.8%)\n",
      "\n",
      "Phase 3 - DOI → PMID:\n",
      "  PMIDs found: 23,302\n",
      "\n",
      "Phase 4 - Abstract fetch:\n",
      "  Records fetched: 23,173\n",
      "  With abstracts: 20,942\n",
      "\n",
      "Final output: referenced_paper_abstracts.csv\n",
      "  Matched: 47,518 (102.6%)\n",
      "  By category: {'excluded': np.int64(30384), 'included': np.int64(15921), 'awaiting': np.int64(719), 'ongoing': np.int64(494)}\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Summary Statistics\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PIPELINE SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nInput: {len(unique_refs):,} unique references from public health reviews\")\n",
    "\n",
    "print(f\"\\nPhase 1 - Direct extraction:\")\n",
    "direct_doi = unique_refs['extracted_doi'].notna().sum() if 'extracted_doi' in unique_refs.columns else 0\n",
    "print(f\"  DOIs extracted: {direct_doi:,}\")\n",
    "\n",
    "if PROGRESS_CSV.exists():\n",
    "    crossref_df = pd.read_csv(PROGRESS_CSV)\n",
    "    crossref_found = crossref_df['crossref_doi'].notna().sum()\n",
    "    print(f\"\\nPhase 2 - CrossRef lookup:\")\n",
    "    print(f\"  DOIs found: {crossref_found:,} / {len(crossref_df):,} ({crossref_found/len(crossref_df)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nPhase 3 - DOI → PMID:\")\n",
    "actual_pmids = sum(1 for v in doi_to_pmid.values() if v is not None)\n",
    "print(f\"  PMIDs found: {actual_pmids:,}\")\n",
    "\n",
    "print(f\"\\nPhase 4 - Abstract fetch:\")\n",
    "print(f\"  Records fetched: {len(abstract_records):,}\")\n",
    "print(f\"  With abstracts: {sum(1 for r in abstract_records.values() if r.get('abstract')):,}\")\n",
    "\n",
    "print(f\"\\nFinal output: {OUTPUT_CSV.name}\")\n",
    "print(f\"  Matched: {len(matched_refs):,} ({len(matched_refs)/len(unique_refs)*100:.1f}%)\")\n",
    "print(f\"  By category: {dict(matched_refs['category'].value_counts())}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
