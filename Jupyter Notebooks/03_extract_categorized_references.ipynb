{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "883fb64b",
   "metadata": {},
   "source": [
    "# 03: Extract Categorized References from Cochrane PDFs\n",
    "\n",
    "## Summary\n",
    "This notebook extracts categorized study references from Cochrane review PDFs. Unlike PubMed XML which mixes all references together, the PDFs contain clearly labeled sections for:\n",
    "- **Included studies** - Studies that passed screening criteria (positives)\n",
    "- **Excluded studies** - Studies that were reviewed but rejected (hard negatives)\n",
    "- **Awaiting classification** - Studies pending assessment (excluded from training)\n",
    "\n",
    "**Pipeline Position:** Fourth notebook - extracts structured reference data from PDFs.\n",
    "\n",
    "**What this notebook does:**\n",
    "1. Reads PDF text using pdfplumber\n",
    "2. Identifies reference section boundaries using regex patterns\n",
    "3. Parses individual study identifiers (Author Year format)\n",
    "4. Saves categorized references to CSV\n",
    "\n",
    "**Input:** `Data/cochrane_pdfs/*.pdf`\n",
    "\n",
    "**Output:** `Data/categorized_references.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591b9c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for PDF text extraction\n",
    "%pip install -q pdfplumber pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54324416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths and load required libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "import re\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "notebook_dir = Path.cwd()\n",
    "project_root = notebook_dir if (notebook_dir / \"Data\").exists() else notebook_dir.parent\n",
    "DATA_DIR = project_root / \"Data\"\n",
    "PDF_DIR = DATA_DIR / \"cochrane_pdfs\"\n",
    "OUTPUT_CSV = DATA_DIR / \"categorized_references.csv\"\n",
    "\n",
    "pdf_files = list(PDF_DIR.glob(\"*.pdf\"))\n",
    "print(f\"Found {len(pdf_files)} PDFs to process\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a396d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to extract text and parse reference sections\n",
    "\n",
    "def extract_pdf_text(pdf_path: Path) -> str:\n",
    "    \"\"\"Extract all text from a PDF file.\"\"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text + \"\\n\\n\"\n",
    "    return text\n",
    "\n",
    "def extract_reference_sections(text: str) -> Dict[str, str]:\n",
    "    \"\"\"Extract text for included, excluded, and awaiting classification sections.\"\"\"\n",
    "    sections = {}\n",
    "    \n",
    "    # Pattern for included studies\n",
    "    included_match = re.search(\n",
    "        r'References to studies included in this review(.*?)(?=References to studies excluded|References to studies awaiting|Additional references|ADDITIONAL TABLES|DATA AND ANALYSES|CHARACTERISTICS OF STUDIES|$)',\n",
    "        text, re.IGNORECASE | re.DOTALL\n",
    "    )\n",
    "    if included_match:\n",
    "        sections['included'] = included_match.group(1)\n",
    "    \n",
    "    # Pattern for excluded studies\n",
    "    excluded_match = re.search(\n",
    "        r'References to studies excluded from this review(.*?)(?=References to studies awaiting|Additional references|ADDITIONAL TABLES|DATA AND ANALYSES|CHARACTERISTICS OF STUDIES|$)',\n",
    "        text, re.IGNORECASE | re.DOTALL\n",
    "    )\n",
    "    if excluded_match:\n",
    "        sections['excluded'] = excluded_match.group(1)\n",
    "    \n",
    "    # Pattern for awaiting classification\n",
    "    awaiting_match = re.search(\n",
    "        r'References to studies awaiting (?:classification|assessment)(.*?)(?=Additional references|ADDITIONAL TABLES|DATA AND ANALYSES|CHARACTERISTICS OF STUDIES|$)',\n",
    "        text, re.IGNORECASE | re.DOTALL\n",
    "    )\n",
    "    if awaiting_match:\n",
    "        sections['awaiting'] = awaiting_match.group(1)\n",
    "    \n",
    "    return sections\n",
    "\n",
    "def parse_study_ids(section_text: str) -> List[str]:\n",
    "    \"\"\"Extract study identifiers (Author Year format) from section text.\"\"\"\n",
    "    # Pattern matches: AuthorName Year {published/unpublished data only}\n",
    "    pattern = r'([A-Z][a-z]+(?:\\s+et\\s+al\\.?)?\\s+\\d{4}[a-z]?)\\s*\\{(?:published|unpublished)'\n",
    "    matches = re.findall(pattern, section_text)\n",
    "    return [m.strip() for m in matches]\n",
    "\n",
    "def process_pdf(pdf_path: Path) -> List[Dict]:\n",
    "    \"\"\"Process a single PDF and extract all categorized references.\"\"\"\n",
    "    results = []\n",
    "    try:\n",
    "        text = extract_pdf_text(pdf_path)\n",
    "        sections = extract_reference_sections(text)\n",
    "        \n",
    "        # Extract DOI from filename (format: 10.1002-14651858.CDxxxxxx.pubN.pdf)\n",
    "        doi = pdf_path.stem.replace(\"-\", \"/\")\n",
    "        \n",
    "        for category, section_text in sections.items():\n",
    "            study_ids = parse_study_ids(section_text)\n",
    "            for study_id in study_ids:\n",
    "                results.append({\n",
    "                    'review_doi': doi,\n",
    "                    'study_id': study_id,\n",
    "                    'category': category\n",
    "                })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {pdf_path.name}: {e}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e937b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test extraction on a sample PDF\n",
    "if pdf_files:\n",
    "    sample_pdf = pdf_files[0]\n",
    "    print(f\"Testing on: {sample_pdf.name}\")\n",
    "    \n",
    "    results = process_pdf(sample_pdf)\n",
    "    \n",
    "    print(f\"\\nExtracted {len(results)} references:\")\n",
    "    for cat in ['included', 'excluded', 'awaiting']:\n",
    "        count = sum(1 for r in results if r['category'] == cat)\n",
    "        print(f\"  {cat}: {count}\")\n",
    "    \n",
    "    print(\"\\nSample references:\")\n",
    "    for r in results[:5]:\n",
    "        print(f\"  [{r['category']}] {r['study_id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1cbffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all PDFs and collect results\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "all_results = []\n",
    "\n",
    "print(f\"Processing {len(pdf_files)} PDFs...\")\n",
    "for pdf_path in tqdm(pdf_files, desc=\"Extracting references\"):\n",
    "    results = process_pdf(pdf_path)\n",
    "    all_results.extend(results)\n",
    "\n",
    "print(f\"\\nTotal references extracted: {len(all_results):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dae338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame and analyze results\n",
    "refs_df = pd.DataFrame(all_results)\n",
    "\n",
    "print(\"Reference counts by category:\")\n",
    "print(refs_df['category'].value_counts())\n",
    "\n",
    "print(f\"\\nUnique reviews processed: {refs_df['review_doi'].nunique()}\")\n",
    "print(f\"Unique study IDs: {refs_df['study_id'].nunique()}\")\n",
    "\n",
    "# Preview\n",
    "refs_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328dc3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "refs_df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"Saved {len(refs_df):,} categorized references to {OUTPUT_CSV}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXTRACTION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total references: {len(refs_df):,}\")\n",
    "print(f\"  Included (positives): {(refs_df['category'] == 'included').sum():,}\")\n",
    "print(f\"  Excluded (negatives): {(refs_df['category'] == 'excluded').sum():,}\")\n",
    "print(f\"  Awaiting (excluded from training): {(refs_df['category'] == 'awaiting').sum():,}\")\n",
    "print(f\"\\nNext step: Run notebook 04 to build ground truth dataset\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
