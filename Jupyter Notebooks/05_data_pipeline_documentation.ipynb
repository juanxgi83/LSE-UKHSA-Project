{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46ee5eae",
   "metadata": {},
   "source": [
    "# Data Processing Pipeline Documentation\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This notebook provides a comprehensive summary of the data processing pipeline used in the **LSE-UKHSA Systematic Review Screening Project**. The goal of this project is to evaluate how well open-source Large Language Models (LLMs) can screen paper abstracts for inclusion in systematic reviews.\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Pipeline Overview](#1-pipeline-overview)\n",
    "2. [Data Sources](#2-data-sources)\n",
    "3. [Step 1: Obtaining Cochrane Reviews](#3-step-1-obtaining-cochrane-reviews)\n",
    "4. [Step 2: Exploratory Data Analysis](#4-step-2-exploratory-data-analysis)\n",
    "5. [Step 3: Fetching Referenced Paper Abstracts](#5-step-3-fetching-referenced-paper-abstracts)\n",
    "6. [Step 4: Building the Ground Truth Validation Set](#6-step-4-building-the-ground-truth-validation-set)\n",
    "7. [Step 5: LLM Evaluation](#7-step-5-llm-evaluation)\n",
    "8. [Data Files Summary](#8-data-files-summary)\n",
    "9. [Records Excluded Due to Missing Information](#9-records-excluded-due-to-missing-information)\n",
    "10. [Data Samples](#10-data-samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1e417a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Pipeline Overview\n",
    "\n",
    "The data processing pipeline consists of **5 sequential steps**, each implemented in a separate Jupyter notebook:\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────────────────┐\n",
    "│                           DATA PROCESSING PIPELINE                               │\n",
    "├─────────────────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                                  │\n",
    "│  ┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐              │\n",
    "│  │   PubMed API    │───>│ 00_obtain...    │───>│ cochrane_pubmed │              │\n",
    "│  │   (NCBI Entrez) │    │  .ipynb         │    │ _abstracts.csv  │              │\n",
    "│  └─────────────────┘    └─────────────────┘    │ (17,092 reviews)│              │\n",
    "│                                   │            │                  │              │\n",
    "│                                   │            │ cochrane_pubmed │              │\n",
    "│                                   └───────────>│ _references.csv │              │\n",
    "│                                                │ (1.18M edges)   │              │\n",
    "│                                                └────────┬────────┘              │\n",
    "│                                                         │                        │\n",
    "│                                                         v                        │\n",
    "│  ┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐              │\n",
    "│  │   PubMed API    │───>│ 02_fetch...     │───>│ referenced_paper│              │\n",
    "│  │   (NCBI Entrez) │    │  .ipynb         │    │ _abstracts.csv  │              │\n",
    "│  └─────────────────┘    └─────────────────┘    │ (491,529 papers)│              │\n",
    "│                                                └────────┬────────┘              │\n",
    "│                                                         │                        │\n",
    "│                                                         v                        │\n",
    "│                         ┌─────────────────┐    ┌─────────────────┐              │\n",
    "│                         │ 03_build...     │───>│ ground_truth_   │              │\n",
    "│                         │  .ipynb         │    │ validation.csv  │              │\n",
    "│                         └─────────────────┘    │ (1,000 samples) │              │\n",
    "│                                                └────────┬────────┘              │\n",
    "│                                                         │                        │\n",
    "│                                                         v                        │\n",
    "│  ┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐              │\n",
    "│  │   Ollama        │───>│ 04_llm...       │───>│ results/        │              │\n",
    "│  │   (Local LLMs)  │    │  .ipynb         │    │ eval_*.csv      │              │\n",
    "│  └─────────────────┘    └─────────────────┘    └─────────────────┘              │\n",
    "│                                                                                  │\n",
    "└─────────────────────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9658e1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Data Sources\n",
    "\n",
    "### Primary Data Source: PubMed (via NCBI Entrez API)\n",
    "\n",
    "All data was obtained from **PubMed**, the free biomedical literature database maintained by the National Library of Medicine (NLM) at the National Institutes of Health (NIH).\n",
    "\n",
    "| Aspect | Details |\n",
    "|--------|--------|\n",
    "| **API** | NCBI Entrez E-utilities |\n",
    "| **Database** | PubMed |\n",
    "| **Python Library** | BioPython (`Bio.Entrez`) |\n",
    "| **Authentication** | Email required; API key optional (increases rate limit) |\n",
    "| **Rate Limits** | 3 requests/sec without API key, 10 requests/sec with key |\n",
    "\n",
    "### Why Cochrane Reviews?\n",
    "\n",
    "**Cochrane systematic reviews** are considered the gold standard in evidence-based medicine. Each Cochrane review:\n",
    "\n",
    "1. **Clearly defines inclusion criteria** for which studies to include\n",
    "2. **Cites all \"included\" studies** in its reference list\n",
    "3. **Follows rigorous screening protocols** that we can use as ground truth\n",
    "\n",
    "This makes them ideal for evaluating automated screening tools—we know exactly which papers were included after human screening."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56ff4ea",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Step 1: Obtaining Cochrane Reviews\n",
    "\n",
    "**Notebook:** `00_obtain_cochrane_abstracts.ipynb`\n",
    "\n",
    "### Process\n",
    "\n",
    "1. **Search Query:** All articles from the Cochrane Database of Systematic Reviews with abstracts\n",
    "   ```\n",
    "   (\"Cochrane Database Syst Rev\"[Journal]) AND hasabstract[text]\n",
    "   ```\n",
    "\n",
    "2. **Fetching Strategy:** \n",
    "   - Split query by year to avoid PubMed's 9,500 record retrieval limit\n",
    "   - Fetch PMIDs in batches of 1,000\n",
    "   - Fetch MEDLINE records (abstracts) in batches of 50\n",
    "   - Fetch XML records (references) in batches of 50\n",
    "\n",
    "3. **Outputs:**\n",
    "   - `cochrane_pubmed_abstracts.csv`: Review metadata and abstracts\n",
    "   - `cochrane_pubmed_references.csv`: Links between reviews and cited papers\n",
    "\n",
    "### Records Pulled\n",
    "\n",
    "| Dataset | Record Count |\n",
    "|---------|-------------|\n",
    "| Cochrane reviews with abstracts | **17,092** |\n",
    "| Reference edges (review → cited paper) | **1,182,678** |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e9a917",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Step 2: Exploratory Data Analysis\n",
    "\n",
    "**Notebook:** `01_eda_cochrane_data.ipynb`\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "#### Cochrane Reviews Dataset\n",
    "\n",
    "| Statistic | Value |\n",
    "|-----------|-------|\n",
    "| Total reviews | 17,092 |\n",
    "| Reviews with references | 10,105 (59%) |\n",
    "| Reviews without references | 6,987 (41%) |\n",
    "| Missing author info | 33 records |\n",
    "\n",
    "#### Abstract Length Statistics\n",
    "\n",
    "| Metric | Words |\n",
    "|--------|-------|\n",
    "| Mean | 545 |\n",
    "| Median | 478 |\n",
    "| Min | 18 |\n",
    "| Max | 4,774 |\n",
    "| Std Dev | 234 |\n",
    "\n",
    "#### References per Review\n",
    "\n",
    "| Metric | Count |\n",
    "|--------|-------|\n",
    "| Mean | 117 references |\n",
    "| Median | 84 references |\n",
    "| Min | 2 references |\n",
    "| Max | 1,890 references |\n",
    "\n",
    "#### Reference Identifiers\n",
    "\n",
    "| Identifier Type | Count | Percentage |\n",
    "|----------------|-------|------------|\n",
    "| References with PMID | 848,607 | 71.8% |\n",
    "| References with DOI | 141,573 | 12.0% |\n",
    "| References with either | 865,992 | 73.2% |\n",
    "| **Unique papers with PMIDs** | **491,531** | — |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd92971",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Step 3: Fetching Referenced Paper Abstracts\n",
    "\n",
    "**Notebook:** `02_fetch_referenced_abstracts.ipynb`\n",
    "\n",
    "### Process\n",
    "\n",
    "1. **Extract unique PMIDs** from the reference edges (491,531 unique papers)\n",
    "2. **Fetch MEDLINE records** in batches of 200 with exponential backoff for errors\n",
    "3. **Save incrementally** to allow resuming if interrupted\n",
    "4. **Total time:** Approximately 2.5-3 hours due to API rate limits\n",
    "\n",
    "### Records Pulled\n",
    "\n",
    "| Metric | Count |\n",
    "|--------|-------|\n",
    "| Unique PMIDs to fetch | 491,531 |\n",
    "| Total records fetched | 491,529 |\n",
    "| Records with abstracts | **443,977** (90.3%) |\n",
    "| Records without abstracts | 47,552 (9.7%) |\n",
    "\n",
    "### Why Some Records Lack Abstracts\n",
    "\n",
    "- Older papers (pre-1975) often don't have abstracts indexed in PubMed\n",
    "- Some publication types (letters, editorials, book chapters) may not have abstracts\n",
    "- 2 PMIDs could not be retrieved (likely withdrawn or merged records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013ae30f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Step 4: Building the Ground Truth Validation Set\n",
    "\n",
    "**Notebook:** `03_build_ground_truth.ipynb`\n",
    "\n",
    "### Methodology\n",
    "\n",
    "The ground truth dataset contains labeled examples for evaluating LLM screening performance:\n",
    "\n",
    "- **Positive examples (INCLUDED):** Papers that appear in a Cochrane review's reference list — these passed human screening\n",
    "- **Negative examples (EXCLUDED):** Papers from *related* reviews that were NOT included in the current review — realistic \"near-miss\" candidates\n",
    "\n",
    "### Sampling Process\n",
    "\n",
    "```\n",
    "1. Start with 17,092 Cochrane reviews\n",
    "       ↓ Filter: has valid references with PMIDs\n",
    "2. 10,077 reviews with valid reference edges\n",
    "       ↓ Filter: referenced papers have abstracts available\n",
    "3. 10,013 reviews with ≥5 included papers with abstracts\n",
    "       ↓ Filter: inclusion criteria can be parsed from abstract\n",
    "4. 9,660 reviews with extractable criteria (96.5%)\n",
    "       ↓ Random sample\n",
    "5. 100 reviews selected for validation set\n",
    "       ↓ Sample 5 included + 5 excluded papers per review\n",
    "6. Final: 1,000 validation records (500 included + 500 excluded)\n",
    "```\n",
    "\n",
    "### Filtering Statistics\n",
    "\n",
    "| Stage | Records | Notes |\n",
    "|-------|---------|-------|\n",
    "| Total Cochrane reviews | 17,092 | — |\n",
    "| Reviews with references | 10,105 | 6,987 excluded (no reference list) |\n",
    "| Valid reference edges (with PMID) | 848,607 | 334,071 excluded (no PMID) |\n",
    "| Unique papers in reference graph | 491,531 | — |\n",
    "| Papers with abstracts available | 443,977 | 47,554 excluded (no abstract) |\n",
    "| Reviews with ≥5 included papers | 10,013 | 64 excluded (too few papers) |\n",
    "| Reviews with parseable criteria | 9,660 | 353 excluded (criteria not extractable) |\n",
    "| **Final validation set** | **1,000** | 500 included + 500 excluded |\n",
    "\n",
    "### How Negative Examples Were Chosen\n",
    "\n",
    "Negative examples are not random papers—they are **\"near-miss\" papers** that:\n",
    "\n",
    "1. Were included in a *related* Cochrane review (same topic area)\n",
    "2. Were NOT included in the current review\n",
    "3. Have abstracts available\n",
    "\n",
    "This creates a realistic screening challenge where the LLM must distinguish between truly relevant papers and closely related but ultimately excluded papers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e243ae1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Step 5: LLM Evaluation\n",
    "\n",
    "**Notebook:** `04_llm_evaluation.ipynb`\n",
    "\n",
    "### Models Tested\n",
    "\n",
    "| Model | Description |\n",
    "|-------|------------|\n",
    "| **Llama 3.2** | Meta's open-source LLM |\n",
    "| **Mistral** | Mistral AI's open-source model |\n",
    "\n",
    "### Prompting Strategies\n",
    "\n",
    "| Strategy | Description |\n",
    "|----------|------------|\n",
    "| **Zero-shot** | Direct instruction to classify as INCLUDE/EXCLUDE |\n",
    "| **Chain-of-Thought (CoT)** | Step-by-step reasoning before decision |\n",
    "\n",
    "### Evaluation Runs\n",
    "\n",
    "The LLM evaluation was run **twice** to verify reproducibility. There are **8 evaluation files** (2 models × 2 prompts × 2 runs), plus one duplicate file that was created during Run 1.\n",
    "\n",
    "#### Run 1 (January 15, 2026 evening)\n",
    "\n",
    "| File | Model | Prompt | Timestamp | Records |\n",
    "|------|-------|--------|-----------|---------|\n",
    "| `eval_llama3.2_zero_shot_20260115_193605.csv` | Llama 3.2 | Zero-shot | 19:36:05 | 1,000 |\n",
    "| `eval_llama3.2_zero_shot_20260115_201927.csv` | Llama 3.2 | Zero-shot | 20:19:27 | 1,000 ⚠️ *duplicate* |\n",
    "| `eval_llama3.2_cot_20260115_215209.csv` | Llama 3.2 | CoT | 21:52:09 | 1,000 |\n",
    "| `eval_mistral_zero_shot_20260115_231802.csv` | Mistral | Zero-shot | 23:18:02 | 1,000 |\n",
    "| `eval_mistral_cot_20260116_003208.csv` | Mistral | CoT | 00:32:08 | 1,000 |\n",
    "\n",
    "> ⚠️ **Note:** `eval_llama3.2_zero_shot_20260115_201927.csv` is a duplicate of the 19:36:05 file (identical content). This brings the total to 9 files instead of 8.\n",
    "\n",
    "#### Run 2 (January 16, 2026 early morning)\n",
    "\n",
    "| File | Model | Prompt | Timestamp | Records |\n",
    "|------|-------|--------|-----------|---------|\n",
    "| `eval_llama3.2_zero_shot_20260116_025453.csv` | Llama 3.2 | Zero-shot | 02:54:53 | 1,000 |\n",
    "| `eval_llama3.2_cot_20260116_041136.csv` | Llama 3.2 | CoT | 04:11:36 | 1,000 |\n",
    "| `eval_mistral_zero_shot_20260116_050656.csv` | Mistral | Zero-shot | 05:06:56 | 1,000 |\n",
    "| `eval_mistral_cot_20260116_073058.csv` | Mistral | CoT | 07:30:58 | 1,000 |\n",
    "\n",
    "### Results Summary (Run 2 - Final Results)\n",
    "\n",
    "The `model_comparison.csv` contains the final aggregated results from Run 2:\n",
    "\n",
    "| Model | Prompt | Accuracy | Precision | Recall | F1 Score | Cohen's κ | Unclear |\n",
    "|-------|--------|----------|-----------|--------|----------|----------|---------|\n",
    "| **Mistral** | **CoT** | **83.6%** | **83.6%** | **83.7%** | **0.837** | **0.672** | 5 |\n",
    "| Mistral | Zero-shot | 84.5% | 90.8% | 76.8% | 0.832 | 0.690 | 0 |\n",
    "| Llama 3.2 | Zero-shot | 80.9% | 76.4% | 89.4% | 0.824 | 0.618 | 0 |\n",
    "| Llama 3.2 | CoT | 73.9% | 90.1% | 52.9% | 0.667 | 0.476 | 25 |\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Best F1 Score:** Mistral with CoT prompting (0.837) — balanced precision/recall\n",
    "2. **Highest Precision:** Mistral zero-shot (90.8%) — fewer false positives\n",
    "3. **Highest Recall:** Llama 3.2 zero-shot (89.4%) — fewer false negatives\n",
    "4. **Unclear Responses:** CoT prompting caused some unclear responses (5-25 samples)\n",
    "5. **Reproducibility:** Two runs were performed to verify consistency of results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b111d1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Data Files Summary\n",
    "\n",
    "### Primary Data Files\n",
    "\n",
    "| File | Records | Description |\n",
    "|------|---------|-------------|\n",
    "| `cochrane_pubmed_abstracts.csv` | 17,092 | Cochrane review abstracts and metadata |\n",
    "| `cochrane_pubmed_references.csv` | 1,182,678 | Links between reviews and cited papers |\n",
    "| `referenced_paper_abstracts.csv` | 491,529 | Abstracts of papers cited in Cochrane reviews |\n",
    "| `ground_truth_validation_set.csv` | 1,000 | Labeled dataset for LLM evaluation |\n",
    "\n",
    "### Schema: `cochrane_pubmed_abstracts.csv`\n",
    "\n",
    "| Column | Type | Description |\n",
    "|--------|------|-------------|\n",
    "| `pmid` | string | PubMed identifier |\n",
    "| `title` | string | Review title |\n",
    "| `abstract` | string | Full abstract text |\n",
    "| `journal` | string | Journal name |\n",
    "| `year` | string | Publication year |\n",
    "| `authors` | string | Semicolon-separated author list |\n",
    "\n",
    "### Schema: `cochrane_pubmed_references.csv`\n",
    "\n",
    "| Column | Type | Description |\n",
    "|--------|------|-------------|\n",
    "| `citing_pmid` | string | PMID of the Cochrane review |\n",
    "| `ref_pmid` | string | PMID of the cited paper (if available) |\n",
    "| `ref_doi` | string | DOI of the cited paper (if available) |\n",
    "| `ref_title` | string | Citation text of the reference |\n",
    "\n",
    "### Schema: `referenced_paper_abstracts.csv`\n",
    "\n",
    "| Column | Type | Description |\n",
    "|--------|------|-------------|\n",
    "| `pmid` | string | PubMed identifier |\n",
    "| `title` | string | Paper title |\n",
    "| `abstract` | string | Abstract text (may be empty) |\n",
    "| `journal` | string | Journal name |\n",
    "| `year` | string | Publication year |\n",
    "| `authors` | string | Semicolon-separated author list |\n",
    "\n",
    "### Schema: `ground_truth_validation_set.csv`\n",
    "\n",
    "| Column | Type | Description |\n",
    "|--------|------|-------------|\n",
    "| `review_pmid` | string | PMID of the Cochrane review |\n",
    "| `review_title` | string | Title of the review |\n",
    "| `review_objectives` | string | Extracted objectives section |\n",
    "| `review_criteria` | string | Extracted selection criteria |\n",
    "| `paper_pmid` | string | PMID of the candidate paper |\n",
    "| `paper_title` | string | Title of the candidate paper |\n",
    "| `paper_abstract` | string | Abstract of the candidate paper |\n",
    "| `label` | int | 1 = Included, 0 = Excluded |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a878a349",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Records Excluded Due to Missing Information\n",
    "\n",
    "Throughout the pipeline, records were excluded at various stages due to missing or insufficient information:\n",
    "\n",
    "### Stage 1: Cochrane Reviews Without References\n",
    "\n",
    "**6,987 reviews (40.9%)** had no reference list in PubMed. This happens when:\n",
    "- The review is a protocol (planned study, not yet completed)\n",
    "- The review is withdrawn\n",
    "- Reference data wasn't indexed in PubMed\n",
    "\n",
    "### Stage 2: References Without PMIDs\n",
    "\n",
    "**334,071 reference edges (28.2%)** lacked a PMID identifier. This happens when:\n",
    "- The cited paper is not indexed in PubMed (books, grey literature, non-English papers)\n",
    "- The citation is incomplete or malformed\n",
    "- The paper was published before PubMed indexing began\n",
    "\n",
    "### Stage 3: Papers Without Abstracts\n",
    "\n",
    "**47,554 papers (9.7%)** were retrieved but had no abstract text. This happens when:\n",
    "- Older papers (especially pre-1975)\n",
    "- Short publication types (letters, editorials, corrections)\n",
    "- Abstract not included in original publication\n",
    "\n",
    "### Stage 4: Reviews Without Parseable Criteria\n",
    "\n",
    "**353 reviews (3.5%)** could not have inclusion criteria extracted. This happens when:\n",
    "- Abstract uses non-standard structure\n",
    "- Criteria section is labeled differently\n",
    "- Abstract is malformed or incomplete\n",
    "\n",
    "### Summary of Exclusions\n",
    "\n",
    "| Exclusion Reason | Records Excluded | Percentage |\n",
    "|-----------------|-----------------|------------|\n",
    "| Reviews without references | 6,987 | 40.9% of reviews |\n",
    "| References without PMID | 334,071 | 28.2% of ref edges |\n",
    "| Papers without abstract | 47,554 | 9.7% of papers |\n",
    "| Non-parseable criteria | 353 | 3.5% of eligible reviews |\n",
    "| Authors missing | 33 | 0.2% of reviews |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c2af74",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Data Samples\n",
    "\n",
    "Below are examples of what the data looks like at each stage of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c8a9072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: c:\\Users\\juanx\\Documents\\LSE-UKHSA Project\\Data\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "DATA_DIR = Path.cwd().parent / \"Data\" if not (Path.cwd() / \"Data\").exists() else Path.cwd() / \"Data\"\n",
    "print(f\"Data directory: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec991598",
   "metadata": {},
   "source": [
    "### Sample: Cochrane Review Abstract\n",
    "\n",
    "Below is an example of a Cochrane review record showing the structured abstract format typical of systematic reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0e25b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SAMPLE COCHRANE REVIEW\n",
      "================================================================================\n",
      "\n",
      "PMID: 41527994\n",
      "Year: 2026\n",
      "Journal: The Cochrane database of systematic reviews\n",
      "\n",
      "Title:\n",
      "Surgical interventions for treating vesicovaginal fistula in women.\n",
      "\n",
      "Authors:\n",
      "Okada Y; Matsushita T; Hasegawa T; Noma H; Ota E; Achila B; Yoshimura Y...\n",
      "\n",
      "Abstract (first 1000 chars):\n",
      "This is a protocol for a Cochrane Review (intervention). The objectives are as follows: To assess the benefits and harms of surgical interventions for treating vesicovaginal fistula in women....\n"
     ]
    }
   ],
   "source": [
    "# Load and display a sample Cochrane review\n",
    "cochrane = pd.read_csv(DATA_DIR / \"cochrane_pubmed_abstracts.csv\", dtype={\"pmid\": str}, nrows=5)\n",
    "\n",
    "sample_review = cochrane.iloc[0]\n",
    "print(\"=\" * 80)\n",
    "print(\"SAMPLE COCHRANE REVIEW\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nPMID: {sample_review['pmid']}\")\n",
    "print(f\"Year: {sample_review['year']}\")\n",
    "print(f\"Journal: {sample_review['journal']}\")\n",
    "print(f\"\\nTitle:\\n{sample_review['title']}\")\n",
    "print(f\"\\nAuthors:\\n{sample_review['authors'][:200]}...\")\n",
    "print(f\"\\nAbstract (first 1000 chars):\\n{sample_review['abstract'][:1000]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2496353",
   "metadata": {},
   "source": [
    "### Sample: Reference Edges\n",
    "\n",
    "Each row in the references file connects a Cochrane review to one of its cited papers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac51b2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE REFERENCE EDGES (Review → Cited Paper)\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citing_pmid",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ref_pmid",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "ref_doi",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ref_title",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "ffe1ece0-900d-4ecc-88a1-856770c3a50f",
       "rows": [
        [
         "0",
         "41527994",
         null,
         null,
         "Hillary CJ, Osman NI, Hilton P, Chapple CR. The aetiology, treatment, and outcome of urogenital fistulae managed in well- and low-resourced countries: a systematic review. European Urology 2016;70(3):478-92. [DOI: 10.1016/j.eururo.2016.02.015]"
        ],
        [
         "1",
         "41527994",
         null,
         null,
         "Hilton P, Ward A. Epidemiological and surgical aspects of urogenital fistulae: a review of 25 years' experience in southeast Nigeria. International Urogynecology Journal and Pelvic Floor Dysfunction 1998;9(4):189-94. [DOI: 10.1007/BF01901602]"
        ],
        [
         "2",
         "41527994",
         null,
         null,
         "Ahmed S, Genadry R, Asiamah B, Liang M, Tripathi V, Anastasi E. Global, regional and national estimates of obstetric fistula prevalence. BMJ Global Health 2025;10(12):e020877. [DOI: 10.1136/bmjgh-2025-020877]"
        ],
        [
         "3",
         "41527994",
         null,
         null,
         "World Health Organization (WHO). International day to end obstetric fistula: call for quality maternal health care for all. www.emro.who.int/media/news/international-day-to-end-obstetric-fistula-call-for-quality-maternal-health-care-for-all.html (accessed 26 December 2025)."
        ],
        [
         "4",
         "41527994",
         null,
         null,
         "Adler AJ, Ronsmans C, Calvert C, Filippi V. Estimating the prevalence of obstetric fistula: a systematic review and meta-analysis. BMC Pregnancy and Childbirth 2013;13:246. [DOI: 10.1186/1471-2393-13-246]"
        ],
        [
         "5",
         "41527994",
         null,
         null,
         "Ahmed S, Curtis SL, Jamil K, Nahar Q, Rahman M, Huda SN, et al. Obstetric fistula in Bangladesh: estimates from a national survey with clinical validation correction. Lancet Global Health 2022;10:e1347-54. [DOI: 10.1016/S2214-109X(22)00276-5]"
        ],
        [
         "6",
         "41527994",
         null,
         null,
         "Arrowsmith S, Hamlin EC, Wall LL. Obstructed labor injury complex: obstetric fistula formation and the multifaceted morbidity of maternal birth trauma in the developing world. Obstetrical & Gynecological Survey 1996;51(9):568-74. [DOI: 10.1097/00006254-199609000-00024]"
        ],
        [
         "7",
         "41527994",
         null,
         null,
         "Cichowitz C, Watt MH, Mchome B, Masenga GG. Delays contributing to the development and repair of obstetric fistula in northern Tanzania. International Urogynecology Journal 2018;29(3):397-405. [DOI: 10.1007/s00192-017-3416-2]"
        ],
        [
         "8",
         "41527994",
         null,
         null,
         "Cromwell D, Hilton P. Retrospective cohort study on patterns of care and outcomes of surgical treatment for lower urinary-genital tract fistula among English National Health Service hospitals between 2000 and 2009. BJU International 2013;111(4):E257-62. [DOI: 10.1111/j.1464-410X.2012.11483.x]"
        ],
        [
         "9",
         "41527994",
         null,
         null,
         "Goh J, Romanzi L, Elneil S, Haylen B, Chen G, Ghoniem G, et al. An International Continence Society (ICS) report on the terminology for female pelvic floor fistulas. Neurourology and Urodynamics 2020;39(8):2040-71. [DOI: 10.1002/nau.24508]"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citing_pmid</th>\n",
       "      <th>ref_pmid</th>\n",
       "      <th>ref_doi</th>\n",
       "      <th>ref_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41527994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hillary CJ, Osman NI, Hilton P, Chapple CR. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41527994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hilton P, Ward A. Epidemiological and surgical...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41527994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ahmed S, Genadry R, Asiamah B, Liang M, Tripat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41527994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>World Health Organization (WHO). International...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41527994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Adler AJ, Ronsmans C, Calvert C, Filippi V. Es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>41527994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ahmed S, Curtis SL, Jamil K, Nahar Q, Rahman M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41527994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arrowsmith S, Hamlin EC, Wall LL. Obstructed l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>41527994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cichowitz C, Watt MH, Mchome B, Masenga GG. De...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>41527994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cromwell D, Hilton P. Retrospective cohort stu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>41527994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Goh J, Romanzi L, Elneil S, Haylen B, Chen G, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  citing_pmid ref_pmid  ref_doi  \\\n",
       "0    41527994      NaN      NaN   \n",
       "1    41527994      NaN      NaN   \n",
       "2    41527994      NaN      NaN   \n",
       "3    41527994      NaN      NaN   \n",
       "4    41527994      NaN      NaN   \n",
       "5    41527994      NaN      NaN   \n",
       "6    41527994      NaN      NaN   \n",
       "7    41527994      NaN      NaN   \n",
       "8    41527994      NaN      NaN   \n",
       "9    41527994      NaN      NaN   \n",
       "\n",
       "                                           ref_title  \n",
       "0  Hillary CJ, Osman NI, Hilton P, Chapple CR. Th...  \n",
       "1  Hilton P, Ward A. Epidemiological and surgical...  \n",
       "2  Ahmed S, Genadry R, Asiamah B, Liang M, Tripat...  \n",
       "3  World Health Organization (WHO). International...  \n",
       "4  Adler AJ, Ronsmans C, Calvert C, Filippi V. Es...  \n",
       "5  Ahmed S, Curtis SL, Jamil K, Nahar Q, Rahman M...  \n",
       "6  Arrowsmith S, Hamlin EC, Wall LL. Obstructed l...  \n",
       "7  Cichowitz C, Watt MH, Mchome B, Masenga GG. De...  \n",
       "8  Cromwell D, Hilton P. Retrospective cohort stu...  \n",
       "9  Goh J, Romanzi L, Elneil S, Haylen B, Chen G, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and display sample reference edges\n",
    "refs = pd.read_csv(DATA_DIR / \"cochrane_pubmed_references.csv\", dtype={\"citing_pmid\": str, \"ref_pmid\": str}, nrows=10)\n",
    "\n",
    "print(\"SAMPLE REFERENCE EDGES (Review → Cited Paper)\")\n",
    "print(\"=\" * 80)\n",
    "display(refs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c2fe12",
   "metadata": {},
   "source": [
    "### Sample: Referenced Paper Abstract\n",
    "\n",
    "These are the \"included\" studies that were cited by Cochrane reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42e31473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SAMPLE REFERENCED PAPER (Included in a Cochrane review)\n",
      "================================================================================\n",
      "\n",
      "PMID: 2314794\n",
      "Year: 1990\n",
      "Journal: Obstetrics and gynecology\n",
      "\n",
      "Title:\n",
      "The use of modified Martius graft as an adjunctive technique in vesicovaginal and rectovaginal fistula repair.\n",
      "\n",
      "Abstract:\n",
      "The use of the Martius graft, a labial fibro-fatty tissue graft, is described as an adjunctive technique in the repair of 37 complex fistulas in 35 patients. The graft was used to repair three groups of patients with non-radiation-induced vesicovaginal fistulas: 12 patients with large (greater than 4 cm) obstetric fistulas, six patients with obstetric fistulas that caused urethral sloughing, and six patients with recurrent obstetric or post-hysterectomy fistulas. Five other patients had radiation-induced fistulas, and six others had rectovaginal fistulas. The overall success rate was 86.5%. Anatomical studies undertaken of the graft in a cadaver demonstrated that it is composed of fibroadipose tissue from the labium majus, and not from the bulbocavernosus muscle. It receives its blood supp...\n"
     ]
    }
   ],
   "source": [
    "# Load and display sample referenced paper\n",
    "ref_abstracts = pd.read_csv(DATA_DIR / \"referenced_paper_abstracts.csv\", dtype={\"pmid\": str}, nrows=5)\n",
    "\n",
    "sample_paper = ref_abstracts[ref_abstracts['abstract'].notna()].iloc[0]\n",
    "print(\"=\" * 80)\n",
    "print(\"SAMPLE REFERENCED PAPER (Included in a Cochrane review)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nPMID: {sample_paper['pmid']}\")\n",
    "print(f\"Year: {sample_paper['year']}\")\n",
    "print(f\"Journal: {sample_paper['journal']}\")\n",
    "print(f\"\\nTitle:\\n{sample_paper['title']}\")\n",
    "print(f\"\\nAbstract:\\n{sample_paper['abstract'][:800]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46534f2",
   "metadata": {},
   "source": [
    "### Sample: Ground Truth Validation Records\n",
    "\n",
    "Each validation record pairs a Cochrane review with a candidate paper and a label (1=include, 0=exclude):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0dd8d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EXAMPLE: INCLUDED PAPER (Label = 1)\n",
      "================================================================================\n",
      "\n",
      "Review PMID: 21678351\n",
      "Review Title:\n",
      "Evaluation of follow-up strategies for patients with epithelial ovarian cancer following completion ...\n",
      "\n",
      "Selection Criteria:\n",
      "SELECTION CRITERIA: All relevant randomised controlled trials (RCTs) that evaluated follow-up strategies for patients with epithelial ovarian cancer following completion of primary treatment....\n",
      "\n",
      "Candidate Paper PMID: 11737464\n",
      "Paper Title:\n",
      "A critical evaluation of current protocols for the follow-up of women treated for gynecological malignancies: a pilot study.\n",
      "\n",
      "Paper Abstract:\n",
      "This retrospective review was undertaken to determine the efficacy of routine follow-up in the detection and management of recurrent cancer. The case notes of all women attending a regional cancer center who were diagnosed with cancer in 1997 were reviewed. Of 81 new cancers followed up for a median of 42 months (range 36-48), 14 have recurred after curative treatment and there were six cases of persistent disease. The median number of clinic visits per patient was 3.5 (range 1-16). Eight recurr...\n",
      "\n",
      "Label: 1 (INCLUDED - this paper was cited in the review)\n"
     ]
    }
   ],
   "source": [
    "# Load the validation set\n",
    "validation = pd.read_csv(DATA_DIR / \"ground_truth_validation_set.csv\")\n",
    "\n",
    "# Show an INCLUDED example\n",
    "included = validation[validation['label'] == 1].iloc[0]\n",
    "print(\"=\" * 80)\n",
    "print(\"EXAMPLE: INCLUDED PAPER (Label = 1)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nReview PMID: {included['review_pmid']}\")\n",
    "print(f\"Review Title:\\n{included['review_title'][:100]}...\")\n",
    "print(f\"\\nSelection Criteria:\\n{included['review_criteria'][:400]}...\")\n",
    "print(f\"\\nCandidate Paper PMID: {included['paper_pmid']}\")\n",
    "print(f\"Paper Title:\\n{included['paper_title']}\")\n",
    "print(f\"\\nPaper Abstract:\\n{included['paper_abstract'][:500]}...\")\n",
    "print(f\"\\nLabel: {included['label']} (INCLUDED - this paper was cited in the review)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c750bb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EXAMPLE: EXCLUDED PAPER (Label = 0)\n",
      "================================================================================\n",
      "\n",
      "Review PMID: 21678351\n",
      "Review Title:\n",
      "Evaluation of follow-up strategies for patients with epithelial ovarian cancer following completion ...\n",
      "\n",
      "Selection Criteria:\n",
      "SELECTION CRITERIA: All relevant randomised controlled trials (RCTs) that evaluated follow-up strategies for patients with epithelial ovarian cancer following completion of primary treatment....\n",
      "\n",
      "Candidate Paper PMID: 18363586\n",
      "Paper Title:\n",
      "Estimates of the burden of malaria morbidity in Africa in children under the age of 5 years.\n",
      "\n",
      "Paper Abstract:\n",
      "OBJECTIVE: To estimate the direct burden of malaria among children younger than 5 years in sub-Saharan Africa (SSA) for the year 2000, as part of a wider initiative on burden estimates. METHODS: A systematic literature review was undertaken in June 2003. Severe malaria outcomes (cerebral malaria, severe malarial anaemia and respiratory distress) and non-severe malaria data were abstracted separately, together with information on the characteristics of each study and its population. Population ch...\n",
      "\n",
      "Label: 0 (EXCLUDED - from a related review, NOT cited in this review)\n"
     ]
    }
   ],
   "source": [
    "# Show an EXCLUDED example\n",
    "excluded = validation[validation['label'] == 0].iloc[0]\n",
    "print(\"=\" * 80)\n",
    "print(\"EXAMPLE: EXCLUDED PAPER (Label = 0)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nReview PMID: {excluded['review_pmid']}\")\n",
    "print(f\"Review Title:\\n{excluded['review_title'][:100]}...\")\n",
    "print(f\"\\nSelection Criteria:\\n{excluded['review_criteria'][:400]}...\")\n",
    "print(f\"\\nCandidate Paper PMID: {excluded['paper_pmid']}\")\n",
    "print(f\"Paper Title:\\n{excluded['paper_title']}\")\n",
    "print(f\"\\nPaper Abstract:\\n{excluded['paper_abstract'][:500]}...\")\n",
    "print(f\"\\nLabel: {excluded['label']} (EXCLUDED - from a related review, NOT cited in this review)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96497f67",
   "metadata": {},
   "source": [
    "### Sample: LLM Evaluation Results\n",
    "\n",
    "Each evaluation run produces predictions that can be compared to the ground truth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0ad1e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL COMPARISON RESULTS - RUN 2 (sorted by F1 score)\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prompt_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "recall",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "f1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "kappa",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "n_valid",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "n_unclear",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "5e7eca7a-1402-40c1-bad4-5e2c069d9c2b",
       "rows": [
        [
         "0",
         "mistral",
         "cot",
         "0.836",
         "0.836",
         "0.837",
         "0.837",
         "0.672",
         "995",
         "5"
        ],
        [
         "1",
         "mistral",
         "zero_shot",
         "0.845",
         "0.908",
         "0.768",
         "0.832",
         "0.69",
         "1000",
         "0"
        ],
        [
         "2",
         "llama3.2",
         "zero_shot",
         "0.809",
         "0.764",
         "0.894",
         "0.824",
         "0.618",
         "1000",
         "0"
        ],
        [
         "3",
         "llama3.2",
         "cot",
         "0.739",
         "0.901",
         "0.529",
         "0.667",
         "0.476",
         "975",
         "25"
        ]
       ],
       "shape": {
        "columns": 9,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prompt_type</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>kappa</th>\n",
       "      <th>n_valid</th>\n",
       "      <th>n_unclear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mistral</td>\n",
       "      <td>cot</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.672</td>\n",
       "      <td>995</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mistral</td>\n",
       "      <td>zero_shot</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.690</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llama3.2</td>\n",
       "      <td>zero_shot</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.618</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama3.2</td>\n",
       "      <td>cot</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.476</td>\n",
       "      <td>975</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model prompt_type  accuracy  precision  recall     f1  kappa  n_valid  \\\n",
       "0   mistral         cot     0.836      0.836   0.837  0.837  0.672      995   \n",
       "1   mistral   zero_shot     0.845      0.908   0.768  0.832  0.690     1000   \n",
       "2  llama3.2   zero_shot     0.809      0.764   0.894  0.824  0.618     1000   \n",
       "3  llama3.2         cot     0.739      0.901   0.529  0.667  0.476      975   \n",
       "\n",
       "   n_unclear  \n",
       "0          5  \n",
       "1          0  \n",
       "2          0  \n",
       "3         25  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model comparison results (Run 2 - final results)\n",
    "results = pd.read_csv(DATA_DIR / \"results\" / \"model_comparison.csv\")\n",
    "\n",
    "print(\"MODEL COMPARISON RESULTS - RUN 2 (sorted by F1 score)\")\n",
    "print(\"=\" * 80)\n",
    "display(results.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4dd8304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPARISON: RUN 1 vs RUN 2\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Prompt",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Run 1 F1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Run 2 F1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Δ F1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Run 1 Acc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Run 2 Acc",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "9723d0c9-3852-4fb6-a832-1268318676d7",
       "rows": [
        [
         "0",
         "Llama 3.2",
         "Zero-shot",
         "0.721",
         "0.824",
         "0.103",
         "0.647",
         "0.809"
        ],
        [
         "1",
         "Llama 3.2",
         "CoT",
         "0.643",
         "0.667",
         "0.024",
         "0.704",
         "0.739"
        ],
        [
         "2",
         "Mistral",
         "Zero-shot",
         "0.801",
         "0.832",
         "0.031",
         "0.811",
         "0.845"
        ],
        [
         "3",
         "Mistral",
         "CoT",
         "0.576",
         "0.837",
         "0.261",
         "0.688",
         "0.836"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Run 1 F1</th>\n",
       "      <th>Run 2 F1</th>\n",
       "      <th>Δ F1</th>\n",
       "      <th>Run 1 Acc</th>\n",
       "      <th>Run 2 Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Llama 3.2</td>\n",
       "      <td>Zero-shot</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.647</td>\n",
       "      <td>0.809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Llama 3.2</td>\n",
       "      <td>CoT</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mistral</td>\n",
       "      <td>Zero-shot</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mistral</td>\n",
       "      <td>CoT</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model     Prompt  Run 1 F1  Run 2 F1   Δ F1  Run 1 Acc  Run 2 Acc\n",
       "0  Llama 3.2  Zero-shot     0.721     0.824  0.103      0.647      0.809\n",
       "1  Llama 3.2        CoT     0.643     0.667  0.024      0.704      0.739\n",
       "2    Mistral  Zero-shot     0.801     0.832  0.031      0.811      0.845\n",
       "3    Mistral        CoT     0.576     0.837  0.261      0.688      0.836"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Run 1 vs Run 2 results\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def compute_metrics_from_file(filepath):\n",
    "    \"\"\"Compute metrics from an evaluation result file.\"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    # Handle different column names between runs\n",
    "    if 'true_label' in df.columns:\n",
    "        y_true = df['true_label']\n",
    "    else:\n",
    "        y_true = df['label']\n",
    "    \n",
    "    if 'prediction' in df.columns:\n",
    "        pred_col = df['prediction']\n",
    "        if pred_col.dtype == 'object':\n",
    "            # String predictions: 'include'/'exclude'\n",
    "            valid = pred_col.isin(['include', 'exclude'])\n",
    "            y_pred = (pred_col == 'include').astype(int)\n",
    "        else:\n",
    "            # Numeric predictions\n",
    "            valid = pred_col.isin([0, 1])\n",
    "            y_pred = pred_col\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    df_valid = df[valid]\n",
    "    y_true = y_true[valid]\n",
    "    y_pred = y_pred[valid]\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred, zero_division=0),\n",
    "        'recall': recall_score(y_true, y_pred, zero_division=0),\n",
    "        'f1': f1_score(y_true, y_pred, zero_division=0),\n",
    "        'n_valid': len(df_valid),\n",
    "        'n_total': len(df)\n",
    "    }\n",
    "\n",
    "# Run 1 files\n",
    "run1_files = {\n",
    "    ('Llama 3.2', 'Zero-shot'): 'eval_llama3.2_zero_shot_20260115_193605.csv',\n",
    "    ('Llama 3.2', 'CoT'): 'eval_llama3.2_cot_20260115_215209.csv',\n",
    "    ('Mistral', 'Zero-shot'): 'eval_mistral_zero_shot_20260115_231802.csv',\n",
    "    ('Mistral', 'CoT'): 'eval_mistral_cot_20260116_003208.csv',\n",
    "}\n",
    "\n",
    "# Run 2 files\n",
    "run2_files = {\n",
    "    ('Llama 3.2', 'Zero-shot'): 'eval_llama3.2_zero_shot_20260116_025453.csv',\n",
    "    ('Llama 3.2', 'CoT'): 'eval_llama3.2_cot_20260116_041136.csv',\n",
    "    ('Mistral', 'Zero-shot'): 'eval_mistral_zero_shot_20260116_050656.csv',\n",
    "    ('Mistral', 'CoT'): 'eval_mistral_cot_20260116_073058.csv',\n",
    "}\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"COMPARISON: RUN 1 vs RUN 2\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "comparison_data = []\n",
    "for (model, prompt), file1 in run1_files.items():\n",
    "    file2 = run2_files[(model, prompt)]\n",
    "    try:\n",
    "        m1 = compute_metrics_from_file(DATA_DIR / \"results\" / file1)\n",
    "        m2 = compute_metrics_from_file(DATA_DIR / \"results\" / file2)\n",
    "        if m1 and m2:\n",
    "            comparison_data.append({\n",
    "                'Model': model,\n",
    "                'Prompt': prompt,\n",
    "                'Run 1 F1': m1['f1'],\n",
    "                'Run 2 F1': m2['f1'],\n",
    "                'Δ F1': m2['f1'] - m1['f1'],\n",
    "                'Run 1 Acc': m1['accuracy'],\n",
    "                'Run 2 Acc': m2['accuracy'],\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {model} {prompt}: {e}\")\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "display(comparison_df.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e14f0d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SAMPLE LLM RESPONSE (Mistral with Chain-of-Thought - Run 2)\n",
      "================================================================================\n",
      "\n",
      "Paper PMID: 11737464\n",
      "True Label: INCLUDE\n",
      "Prediction: INCLUDE\n",
      "\n",
      "LLM Reasoning (truncated):\n",
      " 1. The main topic of this paper is the evaluation of follow-up strategies for patients with cancer (epithelial ovarian cancer in this case), focusing on their efficacy in detecting and managing recurrent cancer.\n",
      "2. This paper indeed relates to the systematic review topic as it evaluates different follow-up strategies for patients with epithelial ovarian cancer after primary treatment, which aligns with the systematic review's focus on the same topic.\n",
      "3. The paper appears to provide relevant evi\n"
     ]
    }
   ],
   "source": [
    "# Show a sample LLM response with reasoning (Chain-of-Thought)\n",
    "# Use the Run 2 file which has the raw_response column\n",
    "eval_file = DATA_DIR / \"results\" / \"eval_mistral_cot_20260116_073058.csv\"\n",
    "if eval_file.exists():\n",
    "    eval_df = pd.read_csv(eval_file, nrows=3)\n",
    "    sample = eval_df.iloc[0]\n",
    "    print(\"=\" * 80)\n",
    "    print(\"SAMPLE LLM RESPONSE (Mistral with Chain-of-Thought - Run 2)\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nPaper PMID: {sample['paper_pmid']}\")\n",
    "    # Handle different column names\n",
    "    label_col = 'true_label' if 'true_label' in sample.index else 'label'\n",
    "    print(f\"True Label: {'INCLUDE' if sample[label_col] == 1 else 'EXCLUDE'}\")\n",
    "    pred = sample['prediction']\n",
    "    print(f\"Prediction: {pred.upper() if isinstance(pred, str) else ('INCLUDE' if pred == 1 else 'EXCLUDE')}\")\n",
    "    # Show raw response if available\n",
    "    if 'raw_response' in sample.index:\n",
    "        print(f\"\\nLLM Reasoning (truncated):\\n{sample['raw_response']}\")\n",
    "    elif 'response' in sample.index:\n",
    "        print(f\"\\nLLM Response:\\n{sample['response']}\")\n",
    "else:\n",
    "    print(\"Evaluation file not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcf8146",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Appendix: Quick Reference\n",
    "\n",
    "### Notebook Execution Order\n",
    "\n",
    "| # | Notebook | Time | Output |\n",
    "|---|----------|------|--------|\n",
    "| 1 | `00_obtain_cochrane_abstracts.ipynb` | ~1 hour | 2 CSV files |\n",
    "| 2 | `01_eda_cochrane_data.ipynb` | < 1 min | Analysis/plots |\n",
    "| 3 | `02_fetch_referenced_abstracts.ipynb` | 2.5-3 hours | 1 CSV file |\n",
    "| 4 | `03_build_ground_truth.ipynb` | < 1 min | 1 CSV file |\n",
    "| 5 | `04_llm_evaluation.ipynb` | Several hours | Multiple CSV files |\n",
    "\n",
    "### Evaluation Files Inventory\n",
    "\n",
    "| Run | Model | Prompt | Filename | Notes |\n",
    "|-----|-------|--------|----------|-------|\n",
    "| 1 | Llama 3.2 | Zero-shot | `eval_llama3.2_zero_shot_20260115_193605.csv` | |\n",
    "| 1 | Llama 3.2 | Zero-shot | `eval_llama3.2_zero_shot_20260115_201927.csv` | ⚠️ Duplicate |\n",
    "| 1 | Llama 3.2 | CoT | `eval_llama3.2_cot_20260115_215209.csv` | |\n",
    "| 1 | Mistral | Zero-shot | `eval_mistral_zero_shot_20260115_231802.csv` | |\n",
    "| 1 | Mistral | CoT | `eval_mistral_cot_20260116_003208.csv` | |\n",
    "| 2 | Llama 3.2 | Zero-shot | `eval_llama3.2_zero_shot_20260116_025453.csv` | |\n",
    "| 2 | Llama 3.2 | CoT | `eval_llama3.2_cot_20260116_041136.csv` | |\n",
    "| 2 | Mistral | Zero-shot | `eval_mistral_zero_shot_20260116_050656.csv` | |\n",
    "| 2 | Mistral | CoT | `eval_mistral_cot_20260116_073058.csv` | |\n",
    "\n",
    "**Total: 9 files (8 unique runs + 1 duplicate)**\n",
    "\n",
    "### Key Numbers to Remember\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| Cochrane reviews | 17,092 |\n",
    "| Reference edges | 1,182,678 |\n",
    "| References with PMIDs | 848,607 (71.8%) |\n",
    "| Unique cited papers | 491,531 |\n",
    "| Papers with abstracts | 443,977 (90.3%) |\n",
    "| Validation set size | 1,000 (balanced) |\n",
    "| Best LLM F1 score | 0.837 (Mistral CoT) |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
