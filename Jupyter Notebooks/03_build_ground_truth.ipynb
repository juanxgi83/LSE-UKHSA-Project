{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8251b318",
   "metadata": {},
   "source": [
    "# Building the Ground Truth Validation Set\n",
    "\n",
    "**Summary:** In this notebook, I create an annotated dataset to evaluate how well LLMs can screen papers for systematic reviews. I need both positive examples (papers that were included in a review) and negative examples (papers that were not included).\n",
    "\n",
    "**What I do:**\n",
    "1. I load the Cochrane reviews, their references, and the fetched paper abstracts\n",
    "2. I extract inclusion/exclusion criteria from each Cochrane review abstract\n",
    "3. For positive examples: I sample papers that appear in a review's reference list (these passed screening)\n",
    "4. For negative examples: I sample papers from related reviews that were NOT included in this review (realistic \"near-miss\" papers)\n",
    "5. I create a balanced dataset of 1,000 records (500 included, 500 excluded)\n",
    "\n",
    "**Output:** `ground_truth_validation_set.csv` with review criteria, paper abstracts, and include/exclude labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93a01d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: c:\\Users\\juanx\\Documents\\LSE-UKHSA Project\\Data\n"
     ]
    }
   ],
   "source": [
    "# I load the required libraries and set up file paths\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "DATA_DIR = Path.cwd().parent / \"Data\" if not (Path.cwd() / \"Data\").exists() else Path.cwd() / \"Data\"\n",
    "ABSTRACTS_CSV = DATA_DIR / \"cochrane_pubmed_abstracts.csv\"\n",
    "REFERENCES_CSV = DATA_DIR / \"cochrane_pubmed_references.csv\"\n",
    "REF_ABSTRACTS_CSV = DATA_DIR / \"referenced_paper_abstracts.csv\"\n",
    "OUTPUT_CSV = DATA_DIR / \"ground_truth_validation_set.csv\"\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0164c959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n",
      "Cochrane reviews: 17,092\n",
      "Reference edges: 1,182,678\n",
      "Referenced paper abstracts: 491,529\n"
     ]
    }
   ],
   "source": [
    "# I load all three datasets: Cochrane reviews, references, and paper abstracts\n",
    "print(\"Loading datasets...\")\n",
    "cochrane = pd.read_csv(ABSTRACTS_CSV, dtype={\"pmid\": str, \"year\": str})\n",
    "refs = pd.read_csv(REFERENCES_CSV, dtype={\"citing_pmid\": str, \"ref_pmid\": str})\n",
    "ref_abstracts = pd.read_csv(REF_ABSTRACTS_CSV, dtype={\"pmid\": str, \"year\": str})\n",
    "\n",
    "print(f\"Cochrane reviews: {len(cochrane):,}\")\n",
    "print(f\"Reference edges: {len(refs):,}\")\n",
    "print(f\"Referenced paper abstracts: {len(ref_abstracts):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8cc1bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid reference edges (with PMID): 848,607\n",
      "Reviews with valid references: 10,077\n",
      "Unique papers in reference graph: 491,531\n"
     ]
    }
   ],
   "source": [
    "# I build mappings: which papers are included in each review, and which reviews include each paper\n",
    "refs_valid = refs[refs[\"ref_pmid\"].notna() & (refs[\"ref_pmid\"] != \"\")].copy()\n",
    "print(f\"Valid reference edges (with PMID): {len(refs_valid):,}\")\n",
    "\n",
    "review_to_included = refs_valid.groupby(\"citing_pmid\")[\"ref_pmid\"].apply(set).to_dict()\n",
    "print(f\"Reviews with valid references: {len(review_to_included):,}\")\n",
    "\n",
    "paper_to_reviews = defaultdict(set)\n",
    "for review, papers in review_to_included.items():\n",
    "    for paper in papers:\n",
    "        paper_to_reviews[paper].add(review)\n",
    "\n",
    "print(f\"Unique papers in reference graph: {len(paper_to_reviews):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40e5ce4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papers with abstracts: 443,977\n",
      "Reviews with >= 5 included papers (with abstracts): 10,013\n"
     ]
    }
   ],
   "source": [
    "# I filter to only keep papers that have abstracts available\n",
    "papers_with_abstracts = set(ref_abstracts[ref_abstracts[\"abstract\"].notna() & (ref_abstracts[\"abstract\"] != \"\")][\"pmid\"])\n",
    "print(f\"Papers with abstracts: {len(papers_with_abstracts):,}\")\n",
    "\n",
    "review_to_included_filtered = {\n",
    "    review: papers & papers_with_abstracts\n",
    "    for review, papers in review_to_included.items()\n",
    "}\n",
    "\n",
    "MIN_INCLUDED = 5\n",
    "eligible_reviews = {r: p for r, p in review_to_included_filtered.items() if len(p) >= MIN_INCLUDED}\n",
    "print(f\"Reviews with >= {MIN_INCLUDED} included papers (with abstracts): {len(eligible_reviews):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2228b7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I define a function to extract inclusion criteria from Cochrane abstract text\n",
    "def extract_criteria_from_abstract(abstract: str) -> dict:\n",
    "    \"\"\"Extract the selection criteria section from a Cochrane abstract.\"\"\"\n",
    "    if not abstract or pd.isna(abstract):\n",
    "        return {\"objectives\": \"\", \"criteria\": \"\", \"full_context\": \"\"}\n",
    "    \n",
    "    result = {\"objectives\": \"\", \"criteria\": \"\", \"full_context\": abstract}\n",
    "    text = abstract.upper()\n",
    "    \n",
    "    criteria_match = re.search(\n",
    "        r\"(SELECTION CRITERIA|ELIGIBILITY CRITERIA|TYPES OF STUDIES|INCLUSION CRITERIA)[:\\s]*(.*?)(?=(SEARCH METHODS|DATA COLLECTION|MAIN RESULTS|AUTHORS|$))\",\n",
    "        text, re.DOTALL\n",
    "    )\n",
    "    if criteria_match:\n",
    "        start, end = criteria_match.start(), criteria_match.end()\n",
    "        result[\"criteria\"] = abstract[start:end].strip()\n",
    "    \n",
    "    obj_match = re.search(\n",
    "        r\"(OBJECTIVE[S]?|RATIONALE|BACKGROUND)[:\\s]*(.*?)(?=(SELECTION CRITERIA|SEARCH METHODS|ELIGIBILITY|TYPES OF|DATA COLLECTION|$))\",\n",
    "        text, re.DOTALL\n",
    "    )\n",
    "    if obj_match:\n",
    "        start, end = obj_match.start(), obj_match.end()\n",
    "        result[\"objectives\"] = abstract[start:end].strip()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5220f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted criteria for 10,013 reviews\n",
      "Reviews with parseable criteria section: 9,660 (96.5%)\n"
     ]
    }
   ],
   "source": [
    "# I extract criteria for all eligible reviews\n",
    "cochrane_lookup = cochrane.set_index(\"pmid\").to_dict(\"index\")\n",
    "\n",
    "review_criteria = {}\n",
    "for review_pmid in eligible_reviews.keys():\n",
    "    if review_pmid in cochrane_lookup:\n",
    "        review_data = cochrane_lookup[review_pmid]\n",
    "        criteria = extract_criteria_from_abstract(review_data.get(\"abstract\", \"\"))\n",
    "        review_criteria[review_pmid] = {\n",
    "            \"title\": review_data.get(\"title\", \"\"),\n",
    "            \"objectives\": criteria[\"objectives\"],\n",
    "            \"criteria\": criteria[\"criteria\"],\n",
    "            \"full_abstract\": review_data.get(\"abstract\", \"\"),\n",
    "        }\n",
    "\n",
    "print(f\"Extracted criteria for {len(review_criteria):,} reviews\")\n",
    "has_criteria = sum(1 for v in review_criteria.values() if v[\"criteria\"])\n",
    "print(f\"Reviews with parseable criteria section: {has_criteria:,} ({100*has_criteria/len(review_criteria):.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "067fefb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I define a function to get negative examples: papers from related reviews that weren't included in this one\n",
    "def get_negative_candidates(review_pmid: str, included_papers: set) -> list:\n",
    "    \"\"\"Get papers included in related reviews but NOT in this review (realistic near-misses).\"\"\"\n",
    "    related_papers = set()\n",
    "    for paper in included_papers:\n",
    "        other_reviews = paper_to_reviews.get(paper, set()) - {review_pmid}\n",
    "        for other_review in other_reviews:\n",
    "            related_papers.update(review_to_included_filtered.get(other_review, set()))\n",
    "    \n",
    "    negative_candidates = related_papers - included_papers\n",
    "    negative_candidates = negative_candidates & papers_with_abstracts\n",
    "    return list(negative_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68345d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eligible reviews with criteria: 9,660\n",
      "Reviews with >= 5 included papers: 9,660\n",
      "Sampled 100 reviews for validation set\n"
     ]
    }
   ],
   "source": [
    "# I set up sampling parameters and select which reviews to use\n",
    "N_REVIEWS = 100\n",
    "POSITIVES_PER_REVIEW = 5\n",
    "NEGATIVES_PER_REVIEW = 5\n",
    "\n",
    "reviews_with_criteria = [r for r in eligible_reviews.keys() if r in review_criteria and review_criteria[r][\"criteria\"]]\n",
    "reviews_with_enough = [r for r in reviews_with_criteria if len(eligible_reviews[r]) >= POSITIVES_PER_REVIEW]\n",
    "sampled_reviews = random.sample(reviews_with_enough, min(N_REVIEWS, len(reviews_with_enough)))\n",
    "\n",
    "print(f\"Eligible reviews with criteria: {len(reviews_with_criteria):,}\")\n",
    "print(f\"Reviews with >= {POSITIVES_PER_REVIEW} included papers: {len(reviews_with_enough):,}\")\n",
    "print(f\"Sampled {len(sampled_reviews)} reviews for validation set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "461328b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 1,000 validation records\n"
     ]
    }
   ],
   "source": [
    "# I generate the validation set by sampling positive and negative examples for each review\n",
    "paper_lookup = ref_abstracts.set_index(\"pmid\").to_dict(\"index\")\n",
    "validation_records = []\n",
    "\n",
    "for review_pmid in sampled_reviews:\n",
    "    included = list(eligible_reviews[review_pmid])\n",
    "    criteria_data = review_criteria[review_pmid]\n",
    "    \n",
    "    pos_sample = random.sample(included, min(POSITIVES_PER_REVIEW, len(included)))\n",
    "    neg_candidates = get_negative_candidates(review_pmid, set(included))\n",
    "    neg_sample = random.sample(neg_candidates, min(NEGATIVES_PER_REVIEW, len(neg_candidates))) if neg_candidates else []\n",
    "    \n",
    "    for paper_pmid in pos_sample:\n",
    "        if paper_pmid in paper_lookup:\n",
    "            paper = paper_lookup[paper_pmid]\n",
    "            validation_records.append({\n",
    "                \"review_pmid\": review_pmid,\n",
    "                \"review_title\": criteria_data[\"title\"],\n",
    "                \"review_objectives\": criteria_data[\"objectives\"],\n",
    "                \"review_criteria\": criteria_data[\"criteria\"],\n",
    "                \"paper_pmid\": paper_pmid,\n",
    "                \"paper_title\": paper.get(\"title\", \"\"),\n",
    "                \"paper_abstract\": paper.get(\"abstract\", \"\"),\n",
    "                \"label\": 1,\n",
    "            })\n",
    "    \n",
    "    for paper_pmid in neg_sample:\n",
    "        if paper_pmid in paper_lookup:\n",
    "            paper = paper_lookup[paper_pmid]\n",
    "            validation_records.append({\n",
    "                \"review_pmid\": review_pmid,\n",
    "                \"review_title\": criteria_data[\"title\"],\n",
    "                \"review_objectives\": criteria_data[\"objectives\"],\n",
    "                \"review_criteria\": criteria_data[\"criteria\"],\n",
    "                \"paper_pmid\": paper_pmid,\n",
    "                \"paper_title\": paper.get(\"title\", \"\"),\n",
    "                \"paper_abstract\": paper.get(\"abstract\", \"\"),\n",
    "                \"label\": 0,\n",
    "            })\n",
    "\n",
    "print(f\"Generated {len(validation_records):,} validation records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9eed72f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Summary:\n",
      "  Total records: 1,000\n",
      "  Unique reviews: 100\n",
      "  Unique papers: 993\n",
      "\n",
      "Label distribution:\n",
      "label\n",
      "Included    500\n",
      "Excluded    500\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Balance: 50.0% positive\n"
     ]
    }
   ],
   "source": [
    "# I convert to DataFrame and check the label balance\n",
    "validation_df = pd.DataFrame(validation_records)\n",
    "\n",
    "print(\"Validation Set Summary:\")\n",
    "print(f\"  Total records: {len(validation_df):,}\")\n",
    "print(f\"  Unique reviews: {validation_df['review_pmid'].nunique()}\")\n",
    "print(f\"  Unique papers: {validation_df['paper_pmid'].nunique()}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(validation_df[\"label\"].value_counts().rename({1: \"Included\", 0: \"Excluded\"}))\n",
    "print(f\"\\nBalance: {validation_df['label'].mean():.1%} positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9a6711e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set already exists at: c:\\Users\\juanx\\Documents\\LSE-UKHSA Project\\Data\\ground_truth_validation_set.csv\n",
      "File size: 2.89 MB\n",
      "Skipping save. Delete the file to regenerate.\n"
     ]
    }
   ],
   "source": [
    "# I save the validation set to CSV (skip if file already exists)\n",
    "if OUTPUT_CSV.exists():\n",
    "    print(f\"Validation set already exists at: {OUTPUT_CSV}\")\n",
    "    print(f\"File size: {OUTPUT_CSV.stat().st_size / 1024 / 1024:.2f} MB\")\n",
    "    print(\"Skipping save. Delete the file to regenerate.\")\n",
    "else:\n",
    "    validation_df.to_csv(OUTPUT_CSV, index=False)\n",
    "    print(f\"Saved validation set to: {OUTPUT_CSV}\")\n",
    "    print(f\"File size: {OUTPUT_CSV.stat().st_size / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1dc2206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample INCLUDED record:\n",
      "Review: Dynamic compression plating versus locked intramedullary nailing for humeral sha...\n",
      "Criteria: SELECTION CRITERIA: Randomised and quasi-randomised controlled trials comparing compression plates and locked intramedullary nail fixation for humeral shaft fractures in adults....\n",
      "Paper: Operative treatment of humeral shaft fractures.\n",
      "Abstract: The results of the operative treatment of 27 humeral shaft fractures treated at the University of Louisville during a 2-year period were reviewed. The aim of this study was to analyze 1) the indicatio...\n",
      "\n",
      "============================================================\n",
      "\n",
      "Sample EXCLUDED record:\n",
      "Review: Dynamic compression plating versus locked intramedullary nailing for humeral sha...\n",
      "Criteria: SELECTION CRITERIA: Randomised and quasi-randomised controlled trials comparing compression plates and locked intramedullary nail fixation for humeral shaft fractures in adults....\n",
      "Paper: Functional results following fractures of the proximal humerus. A controlled clinical study comparing two periods of immobilization.\n",
      "Abstract: In order to compare 1 and 3 weeks of immobilization following proximal humeral fractures a prospective controlled trial was performed in 85 patients. Clinical follow-up according to the Neer assessmen...\n"
     ]
    }
   ],
   "source": [
    "# I preview sample records to verify the data looks correct\n",
    "print(\"Sample INCLUDED record:\")\n",
    "sample_pos = validation_df[validation_df[\"label\"] == 1].iloc[0]\n",
    "print(f\"Review: {sample_pos['review_title'][:80]}...\")\n",
    "print(f\"Criteria: {sample_pos['review_criteria'][:200]}...\")\n",
    "print(f\"Paper: {sample_pos['paper_title']}\")\n",
    "print(f\"Abstract: {sample_pos['paper_abstract'][:200]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\nSample EXCLUDED record:\")\n",
    "sample_neg = validation_df[validation_df[\"label\"] == 0].iloc[0]\n",
    "print(f\"Review: {sample_neg['review_title'][:80]}...\")\n",
    "print(f\"Criteria: {sample_neg['review_criteria'][:200]}...\")\n",
    "print(f\"Paper: {sample_neg['paper_title']}\")\n",
    "print(f\"Abstract: {sample_neg['paper_abstract'][:200]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
