{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eca35fdb",
   "metadata": {},
   "source": [
    "# 02: Fetch Cochrane PDFs via Wiley TDM API\n",
    "\n",
    "## Summary\n",
    "This notebook downloads Cochrane review PDFs using the Wiley Text and Data Mining (TDM) API. The PDFs contain structured reference sections that properly categorize included vs. excluded studies - information not available in PubMed XML.\n",
    "\n",
    "**Pipeline Position:** Third notebook - downloads source PDFs for extracting categorized references.\n",
    "\n",
    "**What this notebook does:**\n",
    "1. Loads Cochrane review metadata from PubMed (including DOIs)\n",
    "2. Downloads PDFs for each review via Wiley TDM API\n",
    "3. Implements **smart batching with automatic resume** after quota limits\n",
    "4. Tracks download progress in persistent log for interruption recovery\n",
    "5. Saves PDFs to local storage for text extraction\n",
    "\n",
    "**Input:** `Data/cochrane_pubmed_abstracts.csv`\n",
    "\n",
    "**Output:** \n",
    "- `Data/cochrane_pdfs/*.pdf` - Downloaded PDF files\n",
    "- `Data/pdf_download_log.csv` - Persistent download tracking log\n",
    "\n",
    "**Requirements:**\n",
    "- Wiley TDM API token in `.env` file (WILEY_TEXT_AND_DATA_MINING_TOKEN)\n",
    "- Institutional IP access to Cochrane Library content\n",
    "\n",
    "**Important:** PDFs contain proprietary content and must NOT be uploaded to GitHub. They are excluded via .gitignore.\n",
    "\n",
    "## Resumable Download Strategy\n",
    "The download process is designed to handle API quota limits gracefully:\n",
    "- **Persistent tracking:** Download status saved after each PDF\n",
    "- **Smart resume:** Re-running skips already downloaded or permanently failed DOIs\n",
    "- **Quota detection:** Automatically stops on rate limit and reports when to retry\n",
    "- **Batch processing:** Downloads in configurable batches with progress checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "76f1d7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages for PDF download and processing\n",
    "%pip install -q wiley-tdm python-dotenv pandas biopython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dcf40ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wiley TDM Token loaded: ‚úì\n",
      "PDF output directory: c:\\Users\\juanx\\Documents\\LSE-UKHSA Project\\Data\\cochrane_pdfs\n"
     ]
    }
   ],
   "source": [
    "# Set up environment and load credentials\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "\n",
    "notebook_dir = Path.cwd()\n",
    "project_root = notebook_dir if (notebook_dir / \".env\").exists() else notebook_dir.parent\n",
    "env_path = project_root / \".env\"\n",
    "load_dotenv(env_path, override=True)\n",
    "\n",
    "WILEY_TDM_TOKEN = os.getenv(\"WILEY_TEXT_AND_DATA_MINING_TOKEN\")\n",
    "os.environ['TDM_API_TOKEN'] = WILEY_TDM_TOKEN or \"\"\n",
    "\n",
    "DATA_DIR = project_root / \"Data\"\n",
    "PDF_DIR = DATA_DIR / \"cochrane_pdfs\"\n",
    "ABSTRACTS_CSV = DATA_DIR / \"cochrane_pubmed_abstracts.csv\"\n",
    "\n",
    "print(f\"Wiley TDM Token loaded: {'‚úì' if WILEY_TDM_TOKEN else '‚úó'}\")\n",
    "print(f\"PDF output directory: {PDF_DIR}\")\n",
    "\n",
    "if not WILEY_TDM_TOKEN:\n",
    "    raise ValueError(\"WILEY_TEXT_AND_DATA_MINING_TOKEN not set in .env file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "596e4b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 17,298 Cochrane reviews\n",
      "Sample: PMID 17636697 -> DOI 10.1002/14651858.CD002182\n"
     ]
    }
   ],
   "source": [
    "# Load Cochrane reviews and fetch DOIs from PubMed\n",
    "from Bio import Entrez\n",
    "import time\n",
    "import re\n",
    "\n",
    "Entrez.email = os.getenv(\"NCBI_EMAIL\", \"\")\n",
    "Entrez.api_key = os.getenv(\"NCBI_API_KEY\", \"\")\n",
    "\n",
    "abstracts = pd.read_csv(ABSTRACTS_CSV, dtype={\"pmid\": str})\n",
    "print(f\"Loaded {len(abstracts):,} Cochrane reviews\")\n",
    "\n",
    "def get_doi_from_pmid(pmid):\n",
    "    \"\"\"Fetch DOI for a PubMed ID.\"\"\"\n",
    "    try:\n",
    "        handle = Entrez.efetch(db=\"pubmed\", id=pmid, rettype=\"xml\", retmode=\"xml\")\n",
    "        xml = handle.read()\n",
    "        if isinstance(xml, bytes):\n",
    "            xml = xml.decode('utf-8')\n",
    "        handle.close()\n",
    "        doi_match = re.search(r'<ArticleId IdType=\"doi\">([^<]+)</ArticleId>', xml)\n",
    "        return doi_match.group(1) if doi_match else None\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "# Test with a sample\n",
    "sample_pmid = abstracts['pmid'].iloc[0]\n",
    "sample_doi = get_doi_from_pmid(sample_pmid)\n",
    "print(f\"Sample: PMID {sample_pmid} -> DOI {sample_doi}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d02baa91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing download for DOI: 10.1002/14651858.CD002182\n",
      "Result: Existing File\n"
     ]
    }
   ],
   "source": [
    "# Initialize Wiley TDM client and test download\n",
    "from wiley_tdm import TDMClient\n",
    "\n",
    "PDF_DIR.mkdir(parents=True, exist_ok=True)\n",
    "tdm = TDMClient(download_dir=str(PDF_DIR))\n",
    "\n",
    "# Test with a single download\n",
    "if sample_doi:\n",
    "    print(f\"Testing download for DOI: {sample_doi}\")\n",
    "    result = tdm.download_pdf(sample_doi)\n",
    "    print(f\"Result: {result}\")\n",
    "else:\n",
    "    print(\"Could not get DOI for test download\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5ae4a034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total UNIQUE Cochrane entries with valid DOIs: 16,616\n",
      "Year range: 1996 - 2026\n",
      "PDFs already downloaded: 15,277\n",
      "Prior log: 15160 entries, 16 permanent failures, 2 quota failures (will retry)\n",
      "\n",
      "Remaining to download: 1,323\n",
      "Year distribution of remaining:\n",
      "year\n",
      "2026     18\n",
      "2025    129\n",
      "2024     97\n",
      "2023    116\n",
      "2022     12\n",
      "2021     11\n",
      "2020     17\n",
      "2019     80\n",
      "2018     50\n",
      "2017     55\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Smart download tracking - persistent log for resume capability\n",
    "DOWNLOAD_LOG = DATA_DIR / \"pdf_download_log.csv\"\n",
    "DOI_CACHE_FILE = DATA_DIR / \"doi_cache.csv\"\n",
    "\n",
    "# Filter to reviews with valid DOIs (ALL years, ALL types - no filtering!)\n",
    "valid_dois = abstracts[abstracts['doi'].notna() & (abstracts['doi'] != '')].copy()\n",
    "valid_dois['year'] = pd.to_numeric(valid_dois['year'], errors='coerce')\n",
    "\n",
    "# DEDUPLICATE by DOI - same DOI appears multiple times in PubMed data\n",
    "# Keep the most recent version of each review\n",
    "valid_dois = valid_dois.sort_values('year', ascending=False).drop_duplicates(subset=['doi'], keep='first')\n",
    "\n",
    "print(f\"Total UNIQUE Cochrane entries with valid DOIs: {len(valid_dois):,}\")\n",
    "print(f\"Year range: {valid_dois['year'].min():.0f} - {valid_dois['year'].max():.0f}\")\n",
    "\n",
    "# Helper to convert DOI to safe filename\n",
    "def doi_to_filename(doi):\n",
    "    return doi.replace(\"/\", \"-\").replace(\":\", \"_\")\n",
    "\n",
    "valid_dois['filename'] = valid_dois['doi'].apply(doi_to_filename)\n",
    "\n",
    "# Check which PDFs already exist on disk\n",
    "existing_pdfs = set(f.stem for f in PDF_DIR.glob(\"*.pdf\"))\n",
    "print(f\"PDFs already downloaded: {len(existing_pdfs):,}\")\n",
    "\n",
    "# Load existing download log to track failures and avoid re-attempting permanent failures\n",
    "if DOWNLOAD_LOG.exists():\n",
    "    prior_log = pd.read_csv(DOWNLOAD_LOG, dtype={'pmid': str, 'doi': str})\n",
    "    # Consider these as permanent failures (don't retry)\n",
    "    permanent_failures = prior_log[prior_log['status'].isin(['http_403', 'http_404', 'not_wiley'])]['doi'].tolist()\n",
    "    # Quota failures should be retried\n",
    "    quota_failures = prior_log[prior_log['status'].str.contains('http_500|quota', case=False, na=False)]['doi'].tolist()\n",
    "    print(f\"Prior log: {len(prior_log)} entries, {len(permanent_failures)} permanent failures, {len(quota_failures)} quota failures (will retry)\")\n",
    "else:\n",
    "    prior_log = pd.DataFrame()\n",
    "    permanent_failures = []\n",
    "    quota_failures = []\n",
    "    print(\"No prior download log found - starting fresh\")\n",
    "\n",
    "# Determine what needs downloading:\n",
    "# - Not already on disk\n",
    "# - Not a permanent failure (403, 404, non-Wiley)\n",
    "to_download = valid_dois[\n",
    "    (~valid_dois['filename'].isin(existing_pdfs)) & \n",
    "    (~valid_dois['doi'].isin(permanent_failures))\n",
    "].copy()\n",
    "\n",
    "# Sort by year (newest first - often more available)\n",
    "to_download = to_download.sort_values('year', ascending=False)\n",
    "print(f\"\\nRemaining to download: {len(to_download):,}\")\n",
    "print(f\"Year distribution of remaining:\")\n",
    "print(to_download.groupby('year').size().sort_index(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "48a25ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting ROBUST download of 1,323 PDFs\n",
      "   Rate limits: 3/sec AND 60/10min ‚Üí ~360 PDFs/hour max\n",
      "   Retries: 5 attempts with exponential backoff\n",
      "   Estimated time: ~3.7 hours\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5776781eb44b4a72aa7236b5ac6d6138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0/1323 [00:00<?, ?pdf/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   üìä 50 done, 0 failed | 1958/hr | ~0.7hr remaining\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 491s for window to slide...\n",
      "\n",
      "‚è∞ QUOTA EXCEEDED at 11:02:04\n",
      "   Progress so far: 60 downloaded, 0 failed\n",
      "   Waiting 10 minutes for quota reset...\n",
      "   ‚è≥ 1 minutes remaining....\n",
      "‚úì Resuming downloads...\n",
      "\n",
      "   üìä 110 done, 0 failed | 307/hr | ~4.0hr remaining\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 496s for window to slide...\n",
      "\n",
      "‚è∞ QUOTA EXCEEDED at 11:22:06\n",
      "   Progress so far: 120 downloaded, 0 failed\n",
      "   Waiting 10 minutes for quota reset...\n",
      "   ‚è≥ 1 minutes remaining....\n",
      "‚úì Resuming downloads...\n",
      "\n",
      "   üìä 170 done, 0 failed | 245/hr | ~4.7hr remaining\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 496s for window to slide...\n",
      "\n",
      "‚è∞ QUOTA EXCEEDED at 11:42:09\n",
      "   Progress so far: 180 downloaded, 0 failed\n",
      "   Waiting 10 minutes for quota reset...\n",
      "   ‚è≥ 1 minutes remaining....\n",
      "‚úì Resuming downloads...\n",
      "\n",
      "   üìä 230 done, 0 failed | 224/hr | ~4.9hr remaining\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 497s for window to slide...\n",
      "\n",
      "   üìä 280 done, 0 failed | 234/hr | ~4.5hr remaining\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 463s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 7s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 11s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 2s for window to slide...\n",
      "\n",
      "   üìä 330 done, 0 failed | 243/hr | ~4.1hr remaining\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 457s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 4s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 8s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 12s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 4s for window to slide...\n",
      "\n",
      "   üìä 380 done, 0 failed | 250/hr | ~3.8hr remaining\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 2s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 4s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 3s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 459s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 4s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 8s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 12s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 3s for window to slide...\n",
      "\n",
      "   üìä 429 done, 1 failed | 255/hr | ~3.5hr remaining\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 2s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 3s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 4s for window to slide...\n",
      "\n",
      "   üìä 479 done, 1 failed | 280/hr | ~3.0hr remaining\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 457s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 4s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 8s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 12s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 4s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 3s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 5s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 4s for window to slide...\n",
      "\n",
      "   üìä 529 done, 1 failed | 282/hr | ~2.8hr remaining\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 3s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 456s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 4s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 6s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 12s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 4s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 2s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 2s for window to slide...\n",
      "\n",
      "   üìä 579 done, 1 failed | 285/hr | ~2.6hr remaining\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 2s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 2s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 2s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 456s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 5s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 7s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 12s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 3s for window to slide...\n",
      "\n",
      "   üìä 629 done, 1 failed | 286/hr | ~2.4hr remaining\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 2s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 456s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 4s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 6s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 11s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 3s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 9s for window to slide...\n",
      "\n",
      "   üìä 679 done, 1 failed | 288/hr | ~2.2hr remaining\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 448s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 2s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 7s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 11s for window to slide...\n",
      "\n",
      "   üìä 729 done, 1 failed | 289/hr | ~2.1hr remaining\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 8s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 3s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 2s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 5s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 2s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 2s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 4s for window to slide...\n",
      "\n",
      "   üìä 779 done, 1 failed | 306/hr | ~1.8hr remaining\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 452s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 8s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 11s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 9s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 4s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 2s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 4s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 3s for window to slide...\n",
      "\n",
      "   üìä 829 done, 1 failed | 306/hr | ~1.6hr remaining\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 2s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 450s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 8s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 11s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 9s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 3s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 5s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 3s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 4s for window to slide...\n",
      "\n",
      "   üìä 879 done, 1 failed | 306/hr | ~1.4hr remaining\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 3s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 453s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 8s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 11s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 9s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 2s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 5s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 3s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 3s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 5s for window to slide...\n",
      "\n",
      "   üìä 929 done, 1 failed | 306/hr | ~1.3hr remaining\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 4s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 3s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 451s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 7s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 11s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 9s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 2s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 3s for window to slide...\n",
      "\n",
      "   üìä 979 done, 1 failed | 306/hr | ~1.1hr remaining\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 2s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 4s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 2s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 451s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 6s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 11s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 9s for window to slide...\n",
      "\n",
      "   üìä 1024 done, 6 failed | 305/hr | ~1.0hr remaining\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 2s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 3s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 3s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 2s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 2s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 3s for window to slide...\n",
      "\n",
      "   üìä 1070 done, 10 failed | 316/hr | ~0.8hr remaining\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 450s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 7s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 11s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 9s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 5s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 3s for window to slide...\n",
      "\n",
      "   üìä 1119 done, 11 failed | 315/hr | ~0.6hr remaining\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 442s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 6s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 12s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 9s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 4s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 2s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 6s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 3s for window to slide...\n",
      "\n",
      "   üìä 1168 done, 12 failed | 315/hr | ~0.5hr remaining\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 5s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 3s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 436s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 9s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 10s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 10s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 4s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 2s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 6s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 4s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 2s for window to slide...\n",
      "\n",
      "   üìä 1218 done, 12 failed | 314/hr | ~0.3hr remaining\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 7s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 6s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 2s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 437s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 8s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 11s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 10s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 4s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 2s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 2s for window to slide...\n",
      "\n",
      "   üìä 1268 done, 12 failed | 314/hr | ~0.1hr remaining\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 7s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 5s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 2s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 8s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 6s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 3s for window to slide...\n",
      "\n",
      "‚è≥ Hit 60/10min limit - waiting 436s for window to slide...\n",
      "\n",
      "============================================================\n",
      "‚úÖ DOWNLOAD SESSION COMPLETE\n",
      "============================================================\n",
      "Duration: 4.2 hours\n",
      "Downloaded: 1,311 PDFs (600.2 MB)\n",
      "Failed (permanent): 12\n",
      "Rate limit pauses: 3\n",
      "Actual rate: 314 PDFs/hour\n",
      "\n",
      "üìÅ PDFs saved to: c:\\Users\\juanx\\Documents\\LSE-UKHSA Project\\Data\\cochrane_pdfs\n"
     ]
    }
   ],
   "source": [
    "# Resumable PDF downloader with ROBUST rate limiting and auto-retry\n",
    "import requests\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from collections import deque\n",
    "import json\n",
    "\n",
    "# =============================================================================\n",
    "# WILEY API RATE LIMITS (confirmed by Wiley support):\n",
    "#   1) Up to 3 articles per second\n",
    "#   2) Up to 60 requests per 10 minutes\n",
    "#\n",
    "# Strategy: Download quickly (respecting 3/sec), then pause when hitting 60/10min\n",
    "# Expected rate: ~360 PDFs/hour (60 every 10 minutes)\n",
    "# =============================================================================\n",
    "\n",
    "# Configuration\n",
    "REQUESTS_PER_10_MIN = 60  # Wiley's limit\n",
    "WINDOW_SECONDS = 600  # 10 minutes in seconds\n",
    "MIN_DELAY_BETWEEN_REQUESTS = 0.4  # Slightly under 3/sec to be safe\n",
    "MAX_RETRIES = 5  # Retries for connection issues\n",
    "INITIAL_BACKOFF = 30  # Initial wait on failure (seconds)\n",
    "MAX_BACKOFF = 600  # Maximum wait between retries (10 minutes)\n",
    "BATCH_SIZE = 50  # Save progress every N downloads\n",
    "\n",
    "# Track request timestamps for rate limiting\n",
    "request_timestamps = deque(maxlen=REQUESTS_PER_10_MIN)\n",
    "\n",
    "def doi_to_safe_filename(doi):\n",
    "    \"\"\"Convert DOI to safe filename - MUST match the check in cell above.\"\"\"\n",
    "    return doi.replace(\"/\", \"-\").replace(\":\", \"_\")\n",
    "\n",
    "def wait_for_rate_limit():\n",
    "    \"\"\"Wait if we've hit the 60 requests / 10 minutes limit.\"\"\"\n",
    "    now = time.time()\n",
    "    \n",
    "    # Clean old timestamps (older than 10 minutes)\n",
    "    while request_timestamps and (now - request_timestamps[0]) > WINDOW_SECONDS:\n",
    "        request_timestamps.popleft()\n",
    "    \n",
    "    # If we've made 60 requests in the last 10 minutes, wait for oldest to expire\n",
    "    if len(request_timestamps) >= REQUESTS_PER_10_MIN:\n",
    "        oldest = request_timestamps[0]\n",
    "        wait_time = WINDOW_SECONDS - (now - oldest) + 2  # Add 2s buffer\n",
    "        if wait_time > 0:\n",
    "            print(f\"\\n‚è≥ Hit 60/10min limit - waiting {wait_time:.0f}s for window to slide...\")\n",
    "            time.sleep(wait_time)\n",
    "    \n",
    "    # Maintain minimum delay between requests (3/sec limit)\n",
    "    if request_timestamps:\n",
    "        time_since_last = time.time() - request_timestamps[-1]\n",
    "        if time_since_last < MIN_DELAY_BETWEEN_REQUESTS:\n",
    "            time.sleep(MIN_DELAY_BETWEEN_REQUESTS - time_since_last)\n",
    "\n",
    "def download_pdf_with_retry(doi, token, output_dir, max_retries=MAX_RETRIES):\n",
    "    \"\"\"Download PDF with exponential backoff retry logic.\"\"\"\n",
    "    url = f\"https://api.wiley.com/onlinelibrary/tdm/v1/articles/{doi}\"\n",
    "    headers = {\"Wiley-TDM-Client-Token\": token}\n",
    "    \n",
    "    for attempt in range(max_retries + 1):\n",
    "        # Respect rate limit before making request\n",
    "        wait_for_rate_limit()\n",
    "        \n",
    "        try:\n",
    "            # Record this request timestamp\n",
    "            request_timestamps.append(time.time())\n",
    "            \n",
    "            response = requests.get(url, headers=headers, timeout=60)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                content_type = response.headers.get('Content-Type', '')\n",
    "                if 'application/pdf' in content_type and len(response.content) > 1000:\n",
    "                    filename = doi_to_safe_filename(doi) + \".pdf\"\n",
    "                    filepath = output_dir / filename\n",
    "                    with open(filepath, 'wb') as f:\n",
    "                        f.write(response.content)\n",
    "                    return \"success\", len(response.content)\n",
    "                elif 'application/json' in content_type:\n",
    "                    try:\n",
    "                        error_data = response.json()\n",
    "                        if 'quota' in str(error_data).lower():\n",
    "                            return \"quota_exceeded\", 0\n",
    "                    except:\n",
    "                        pass\n",
    "                    return \"api_error\", 0\n",
    "                else:\n",
    "                    return \"empty_response\", 0\n",
    "                    \n",
    "            elif response.status_code == 500:\n",
    "                # Check if it's a quota violation\n",
    "                try:\n",
    "                    if 'application/json' in response.headers.get('Content-Type', ''):\n",
    "                        error_data = response.json()\n",
    "                        if 'quota' in str(error_data).lower() or 'ratelimit' in str(error_data).lower():\n",
    "                            return \"quota_exceeded\", 0\n",
    "                except:\n",
    "                    pass\n",
    "                # HTTP 500 might be temporary - retry with backoff\n",
    "                if attempt < max_retries:\n",
    "                    backoff = min(INITIAL_BACKOFF * (2 ** attempt), MAX_BACKOFF)\n",
    "                    print(f\"\\n‚ö†Ô∏è  HTTP 500 for {doi[:30]}... - retrying in {backoff}s (attempt {attempt+1}/{max_retries})\")\n",
    "                    time.sleep(backoff)\n",
    "                    continue\n",
    "                return \"http_500\", 0\n",
    "                \n",
    "            elif response.status_code in [403, 404]:\n",
    "                # Permanent failures - don't retry\n",
    "                return f\"http_{response.status_code}\", 0\n",
    "                \n",
    "            elif response.status_code in [429, 503]:\n",
    "                # Rate limited or service unavailable - wait and retry\n",
    "                if attempt < max_retries:\n",
    "                    backoff = min(INITIAL_BACKOFF * (2 ** attempt), MAX_BACKOFF)\n",
    "                    print(f\"\\n‚ö†Ô∏è  HTTP {response.status_code} - server busy, waiting {backoff}s...\")\n",
    "                    time.sleep(backoff)\n",
    "                    continue\n",
    "                return f\"http_{response.status_code}\", 0\n",
    "            else:\n",
    "                return f\"http_{response.status_code}\", 0\n",
    "                \n",
    "        except requests.Timeout:\n",
    "            if attempt < max_retries:\n",
    "                backoff = min(INITIAL_BACKOFF * (2 ** attempt), MAX_BACKOFF)\n",
    "                print(f\"\\n‚ö†Ô∏è  Timeout for {doi[:30]}... - retrying in {backoff}s\")\n",
    "                time.sleep(backoff)\n",
    "                continue\n",
    "            return \"timeout\", 0\n",
    "            \n",
    "        except requests.ConnectionError:\n",
    "            if attempt < max_retries:\n",
    "                backoff = min(INITIAL_BACKOFF * (2 ** attempt), MAX_BACKOFF)\n",
    "                print(f\"\\nüîå Connection error - retrying in {backoff}s (attempt {attempt+1}/{max_retries})\")\n",
    "                time.sleep(backoff)\n",
    "                continue\n",
    "            return \"connection_error\", 0\n",
    "            \n",
    "        except Exception as e:\n",
    "            if attempt < max_retries:\n",
    "                backoff = min(INITIAL_BACKOFF * (2 ** attempt), MAX_BACKOFF)\n",
    "                print(f\"\\n‚ö†Ô∏è  Error {type(e).__name__} - retrying in {backoff}s\")\n",
    "                time.sleep(backoff)\n",
    "                continue\n",
    "            return f\"error_{type(e).__name__}\", 0\n",
    "    \n",
    "    return \"max_retries_exceeded\", 0\n",
    "\n",
    "def save_progress(results_log, log_path):\n",
    "    \"\"\"Save current progress to CSV.\"\"\"\n",
    "    if results_log:\n",
    "        log_df = pd.DataFrame(results_log)\n",
    "        if log_path.exists():\n",
    "            existing = pd.read_csv(log_path, dtype={'pmid': str, 'doi': str})\n",
    "            combined = pd.concat([existing, log_df]).drop_duplicates(subset=['doi'], keep='last')\n",
    "            combined.to_csv(log_path, index=False)\n",
    "        else:\n",
    "            log_df.to_csv(log_path, index=False)\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN DOWNLOAD LOOP - Runs until complete, handles all errors gracefully\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"üöÄ Starting ROBUST download of {len(to_download):,} PDFs\")\n",
    "print(f\"   Rate limits: 3/sec AND 60/10min ‚Üí ~360 PDFs/hour max\")\n",
    "print(f\"   Retries: {MAX_RETRIES} attempts with exponential backoff\")\n",
    "print(f\"   Estimated time: ~{len(to_download)/360:.1f} hours\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "success_count = 0\n",
    "fail_count = 0\n",
    "results_log = []\n",
    "total_bytes = 0\n",
    "start_time = datetime.now()\n",
    "rate_limit_waits = 0\n",
    "\n",
    "i = 0\n",
    "pbar = tqdm(total=len(to_download), desc=\"Downloading\", unit=\"pdf\")\n",
    "\n",
    "while i < len(to_download):\n",
    "    row = to_download.iloc[i]\n",
    "    doi = row['doi']\n",
    "    pmid = row['pmid']\n",
    "    \n",
    "    status, file_size = download_pdf_with_retry(doi, WILEY_TDM_TOKEN, PDF_DIR)\n",
    "    \n",
    "    if status == \"success\":\n",
    "        success_count += 1\n",
    "        total_bytes += file_size\n",
    "        pbar.update(1)\n",
    "        i += 1\n",
    "        \n",
    "    elif status == \"quota_exceeded\":\n",
    "        # Unexpected quota hit - wait 10 minutes and retry\n",
    "        rate_limit_waits += 1\n",
    "        print(f\"\\n‚è∞ QUOTA EXCEEDED at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "        print(f\"   Progress so far: {success_count} downloaded, {fail_count} failed\")\n",
    "        print(f\"   Waiting 10 minutes for quota reset...\")\n",
    "        \n",
    "        # Save progress before waiting\n",
    "        save_progress(results_log, DOWNLOAD_LOG)\n",
    "        results_log = []\n",
    "        \n",
    "        # Clear our tracking (server's window may differ)\n",
    "        request_timestamps.clear()\n",
    "        \n",
    "        # Wait with countdown\n",
    "        for remaining in range(600, 0, -60):\n",
    "            print(f\"   ‚è≥ {remaining//60} minutes remaining...\", end='\\r')\n",
    "            time.sleep(min(60, remaining))\n",
    "        print(f\"\\n‚úì Resuming downloads...\")\n",
    "        # Don't increment i - retry the same DOI\n",
    "        continue\n",
    "        \n",
    "    else:\n",
    "        # Permanent failure (403, 404, etc.) - log and move on\n",
    "        fail_count += 1\n",
    "        results_log.append({\n",
    "            'pmid': pmid,\n",
    "            'doi': doi,\n",
    "            'year': row['year'],\n",
    "            'status': status,\n",
    "            'size_bytes': file_size,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        })\n",
    "        pbar.update(1)\n",
    "        i += 1\n",
    "    \n",
    "    # Log successful downloads too\n",
    "    if status == \"success\":\n",
    "        results_log.append({\n",
    "            'pmid': pmid,\n",
    "            'doi': doi,\n",
    "            'year': row['year'],\n",
    "            'status': status,\n",
    "            'size_bytes': file_size,\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        })\n",
    "    \n",
    "    # Save progress periodically\n",
    "    if len(results_log) >= BATCH_SIZE:\n",
    "        save_progress(results_log, DOWNLOAD_LOG)\n",
    "        elapsed = (datetime.now() - start_time).total_seconds() / 3600\n",
    "        rate = success_count / elapsed if elapsed > 0 else 0\n",
    "        remaining_time = (len(to_download) - i) / rate if rate > 0 else 0\n",
    "        print(f\"\\n   üìä {success_count} done, {fail_count} failed | {rate:.0f}/hr | ~{remaining_time:.1f}hr remaining\")\n",
    "        results_log = []\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "# Final save\n",
    "save_progress(results_log, DOWNLOAD_LOG)\n",
    "\n",
    "# =============================================================================\n",
    "# SESSION SUMMARY\n",
    "# =============================================================================\n",
    "elapsed_hours = (datetime.now() - start_time).total_seconds() / 3600\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ DOWNLOAD SESSION COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Duration: {elapsed_hours:.1f} hours\")\n",
    "print(f\"Downloaded: {success_count:,} PDFs ({total_bytes/1024/1024:.1f} MB)\")\n",
    "print(f\"Failed (permanent): {fail_count:,}\")\n",
    "print(f\"Rate limit pauses: {rate_limit_waits}\")\n",
    "print(f\"Actual rate: {success_count/elapsed_hours:.0f} PDFs/hour\" if elapsed_hours > 0 else \"\")\n",
    "print(f\"\\nüìÅ PDFs saved to: {PDF_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e7e7aa4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "OVERALL DOWNLOAD PROGRESS\n",
      "============================================================\n",
      "Total Cochrane reviews with DOIs: 16,616\n",
      "PDFs on disk: 16,588\n",
      "Storage used: 12890.0 MB (12.59 GB)\n",
      "Average PDF size: 796 KB\n",
      "\n",
      "Progress: 99.8% complete\n",
      "Remaining downloadable: ~0\n",
      "\n",
      "Download status breakdown:\n",
      "  success: 16,359\n",
      "  failed: 94\n",
      "  http_404: 28\n",
      "  quota_exceeded: 2\n",
      "\n",
      "üìã Next steps:\n",
      "   ‚úì Enough PDFs to validate pipeline - proceed to notebook 03\n",
      "   ‚úì All available PDFs downloaded!\n"
     ]
    }
   ],
   "source": [
    "# Overall download progress summary\n",
    "pdf_files = list(PDF_DIR.glob(\"*.pdf\"))\n",
    "total_size_mb = sum(p.stat().st_size for p in pdf_files) / (1024 * 1024)\n",
    "\n",
    "# Load full log for analysis\n",
    "if DOWNLOAD_LOG.exists():\n",
    "    full_log = pd.read_csv(DOWNLOAD_LOG, dtype={'pmid': str, 'doi': str})\n",
    "    status_summary = full_log['status'].value_counts()\n",
    "else:\n",
    "    full_log = pd.DataFrame()\n",
    "    status_summary = pd.Series(dtype=int)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"OVERALL DOWNLOAD PROGRESS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total Cochrane reviews with DOIs: {len(valid_dois):,}\")\n",
    "print(f\"PDFs on disk: {len(pdf_files):,}\")\n",
    "print(f\"Storage used: {total_size_mb:.1f} MB ({total_size_mb/1024:.2f} GB)\")\n",
    "print(f\"Average PDF size: {total_size_mb/len(pdf_files)*1024:.0f} KB\" if pdf_files else \"\")\n",
    "print(f\"\\nProgress: {len(pdf_files)/len(valid_dois)*100:.1f}% complete\")\n",
    "\n",
    "# Remaining work\n",
    "remaining = len(valid_dois) - len(pdf_files) - len(full_log[full_log['status'].isin(['http_403', 'http_404'])])\n",
    "print(f\"Remaining downloadable: ~{remaining:,}\")\n",
    "\n",
    "if not status_summary.empty:\n",
    "    print(f\"\\nDownload status breakdown:\")\n",
    "    for status, count in status_summary.items():\n",
    "        print(f\"  {status}: {count:,}\")\n",
    "\n",
    "print(f\"\\nüìã Next steps:\")\n",
    "if len(pdf_files) >= 100:\n",
    "    print(f\"   ‚úì Enough PDFs to validate pipeline - proceed to notebook 03\")\n",
    "if remaining > 0:\n",
    "    print(f\"   ‚Üí Re-run download cell after quota reset to continue\")\n",
    "else:\n",
    "    print(f\"   ‚úì All available PDFs downloaded!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
